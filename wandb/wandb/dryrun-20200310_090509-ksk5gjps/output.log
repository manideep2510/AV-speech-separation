Training data: 50000
Validation data: 5000
3D Conv Out: (None, 50, 32, 32, 64)
3D Conv Out Reshape: (None, 32, 32, 64)
Resnet18 Out: (None, 1, 1, 512)
Resnet18 Linear Out: (None, 256)
Input to GRU: (None, 50, 256)
GRU Out: (None, 50, 29)
Separable Conv ResNet LSTM Pretrain weights loaded
outv: (None, 200, 256)
outa: (None, 1600, 256)
hidden (None, 256)
Traceback (most recent call last):
  File "/data/AV-speech-separation1/main_tasnet_attention1.py", line 103, in <module>
    attention=True, lstm = False, lipnet_pretrained=True,  train_lipnet=False)
  File "/data/AV-speech-separation1/models/tdavss_attention2.py", line 88, in __init__
    self.build()
  File "/data/AV-speech-separation1/models/tdavss_attention2.py", line 154, in build
    self.attn_out,self.attn_states=Bahdanau(name='attention_layer')([self.outv,self.outa1,hidden_state,cell_state, out_state])
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 842, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /data/AV-speech-separation1/models/attention_layers.py:466 call  *
        fake_out, outputs, _ = K.rnn(energy, decoder_out_seq , [hidden_state, out_state])
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py:4156 rnn
        **while_loop_kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py:2675 while_loop
        back_prop=back_prop)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py:198 while_loop
        add_control_dependencies=add_control_dependencies)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py:915 func_graph_from_py_func
        func_outputs = python_func(*func_args, **func_kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py:176 wrapped_body
        outputs = body(*_pack_sequence_as(orig_loop_vars, args))
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py:4145 _step
        new_state.set_shape(state.shape)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:645 set_shape
        raise ValueError(str(e))

    ValueError: Dimension 1 in both shapes must be equal, but are 256 and 512. Shapes are [?,256] and [?,512].

