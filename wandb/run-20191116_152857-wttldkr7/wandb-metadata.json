{
    "gpu_count": 2,
    "cuda": "10.0.130",
    "os": "Linux-4.15.0-46-generic-x86_64-with-Ubuntu-16.04-xenial",
    "heartbeatAt": "2019-11-16T15:29:37.708148",
    "program": "main_tasnet.py",
    "args": [
        "-epochs",
        "2",
        "-batch_size",
        "12",
        "-lr",
        "0.0001"
    ],
    "git": {
        "commit": "5af62a44e5d9b93829b0040da67dab097ff28656",
        "remote": "https://github.com/manideep2510/AV-speech-separation"
    },
    "cpu_count": 12,
    "email": null,
    "python": "3.5.2",
    "jobType": null,
    "gpu": "TITAN Xp",
    "state": "failed",
    "root": "/data/AV-speech-separation1",
    "username": "4014",
    "exitcode": 1,
    "mode": "dryrun",
    "name": "Attention-tasnet-",
    "notes": "Testing. Predict time samples directly.Training with Attention layer, Mish Activation Function, 2 Second clips. 0.35 lr decay if no Val_loss Dec for 2epochs. TasNet with Resnet LSTM Lipnet. Loss is Root of TF L2 Loss",
    "host": "shell2",
    "startedAt": "2019-11-16T15:29:14.137593",
    "executable": "/usr/local/bin/python",
    "project": "av-speech-seperation"
}
