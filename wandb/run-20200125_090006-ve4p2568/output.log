Training data: 100000
Validation data: 6002
3D Conv Out: (None, 50, 32, 32, 64)
3D Conv Out Reshape: (None, 32, 32, 64)
Resnet18 Out: (None, 1, 1, 512)
Resnet18 Linear Out: (None, 256)
Input to GRU: (None, 50, 256)
GRU Out: (None, 50, 29)
ResNet LSTM Pretrain weights loaded
outv: (None, 200, 256)
outa: (None, 200, 256)
hidden (None, 256)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
dec (None, 1, 512)
attn_out: (None, 200, 256)
attn_states: (None, 200, 200)
fusion: (None, 200, 512)

==================================================================================================
Total params: 36,086,046
Trainable params: 17,407,745
Non-trainable params: 18,678,301
__________________________________________________________________________________________________

Model weights path: tdavss_Luong_attention_Normalize_ResNetLSTMLip_236kTrain_2secondsClips_epochs20_lr1e-4_0.35decayNoValDec2epochs_exp1

Epoch 1/20
   1/2778 [..............................] - ETA: 9:51:23 - loss: 45.6398 - snr_acc: -45.6398   2/2778 [..............................] - ETA: 5:53:49 - loss: 45.0842 - snr_acc: -45.0842   3/2778 [..............................] - ETA: 4:35:13 - loss: 43.6620 - snr_acc: -43.6620   4/2778 [..............................] - ETA: 3:58:59 - loss: 48.0292 - snr_acc: -48.0292   5/2778 [..............................] - ETA: 3:35:09 - loss: 49.0489 - snr_acc: -49.0489   6/2778 [..............................] - ETA: 3:18:51 - loss: 48.7291 - snr_acc: -48.7291   7/2778 [..............................] - ETA: 3:07:24 - loss: 49.0180 - snr_acc: -49.0180   8/2778 [..............................] - ETA: 2:58:46 - loss: 49.1253 - snr_acc: -49.1253   9/2778 [..............................] - ETA: 2:51:46 - loss: 49.9682 - snr_acc: -49.9682  10/2778 [..............................] - ETA: 2:47:14 - loss: 50.0328 - snr_acc: -50.0328  11/2778 [..............................] - ETA: 2:42:32 - loss: 50.0449 - snr_acc: -50.0449  12/2778 [..............................] - ETA: 2:38:59 - loss: 50.6045 - snr_acc: -50.6045