Training data: 100000
Validation data: 6002
3D Conv Out: (None, 50, 32, 32, 64)
3D Conv Out Reshape: (None, 32, 32, 64)
Resnet18 Out: (None, 1, 1, 512)
Resnet18 Linear Out: (None, 256)
Input to GRU: (None, 50, 256)
GRU Out: (None, 50, 29)
ResNet LSTM Pretrain weights loaded
outv: (None, 200, 256)
outa: (None, 200, 256)
hidden (None, 256)
Traceback (most recent call last):
  File "main_tasnet_attention.py", line 117, in <module>
    tasnet = TasNet(time_dimensions=200, frequency_bins=257, n_frames=50, attention=True, lipnet_pretrained=True,  train_lipnet=False)
  File "/data/AV-speech-separation1/models/tdavss_attention.py", line 75, in __init__
    self.build()
  File "/data/AV-speech-separation1/models/tdavss_attention.py", line 142, in build
    context_vector, attn_states = attention_layer([self.outa,hidden_state])
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 842, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /data/AV-speech-separation1/models/attention_layers.py:175 call  *
        encoder_out_seq, decoder_out_seq,timestep = inputs

    ValueError: not enough values to unpack (expected 3, got 2)

