Training data: 473178
Validation data: 6002
3D Conv Out: (None, 50, 32, 32, 64)
3D Conv Out Reshape: (None, 32, 32, 64)
Resnet18 Out: (None, 1, 1, 512)
Resnet18 Linear Out: (None, 256)
Input to GRU: (None, 50, 256)
GRU Out: (None, 50, 29)
ResNet LSTM Pretrain weights loaded
outv: (None, 200, 256)
outa: (None, 200, 256)
hidden (None, 256)
[TensorShape([None, 200, 256]), TensorShape([None, 256]), TensorShape([])]
attn_out: (None, 200, 256)
attn_states: (None, 200, 200)
fusion: (None, 200, 512)

==================================================================================================
Total params: 36,480,798
Trainable params: 36,434,206
Non-trainable params: 46,592
__________________________________________________________________________________________________

Model weights path: tdavss_Luong_attention_Normalize_ResNetLSTMLip_236kTrain_2secondsClips_epochs20_lr1e-4_0.35decayNoValDec2epochs_exp4

Epoch 1/20
   1/9858 [..............................] - ETA: 245:08:50 - loss: 40.4179 - snr_acc: -40.4179   2/9858 [..............................] - ETA: 128:20:03 - loss: 41.2144 - snr_acc: -41.2144Traceback (most recent call last):
  File "main_tasnet_attention.py", line 192, in <module>
    callbacks=[reducelronplateau, checkpoint_save_weights, metrics_wandb, LoggingCallback(print_fcn=log_to_file)], verbose=1)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py", line 1297, in fit_generator
    steps_name='steps_per_epoch')
  File "/usr/local/lib/python3.6/dist-packages/wandb/keras/__init__.py", line 104, in new_generator
    return old_generator(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py", line 265, in model_iteration
    batch_outs = batch_function(*batch_data)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py", line 973, in train_on_batch
    class_weight=class_weight, reset_metrics=reset_metrics)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py", line 264, in train_on_batch
    output_loss_metrics=model._output_loss_metrics)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py", line 311, in train_on_batch
    output_loss_metrics=output_loss_metrics))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py", line 268, in _process_single_batch
    grads = tape.gradient(scaled_total_loss, trainable_weights)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py", line 1014, in gradient
    unconnected_gradients=unconnected_gradients)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/imperative_grad.py", line 76, in imperative_grad
    compat.as_str(unconnected_gradients.value))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py", line 138, in _gradient_function
    return grad_fn(mock_op, *out_grads)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_grad.py", line 247, in _MaxPool3DGrad
    data_format=op.get_attr("data_format").decode())
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py", line 5889, in max_pool3d_grad
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File "<string>", line 3, in raise_from
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[16,64,50,33,66] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:MaxPool3DGrad]
