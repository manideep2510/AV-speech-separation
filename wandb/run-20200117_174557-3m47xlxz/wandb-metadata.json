{
    "root": "/data/AV-speech-separation1",
    "program": "main_tasnet.py",
    "git": {
        "remote": "https://github.com/manideep2510/AV-speech-separation",
        "commit": "9724f32bf33e8671412e49d555fa2d00737f6959"
    },
    "email": null,
    "startedAt": "2020-01-17T17:52:13.063380",
    "host": "shell1",
    "username": "4014",
    "executable": "/usr/local/bin/python",
    "os": "Linux-4.15.0-46-generic-x86_64-with-Ubuntu-18.04-bionic",
    "python": "3.6.8",
    "gpu": "TITAN Xp",
    "gpu_count": 2,
    "cpu_count": 12,
    "cuda": "10.0.130",
    "args": [
        "-epochs",
        "20",
        "-batch_size",
        "8",
        "-lr",
        "0.0001"
    ],
    "state": "running",
    "jobType": null,
    "mode": "dryrun",
    "name": "tdavss_freezeLip_attention_norm",
    "notes": "freeze LipNet with attention, Normalize input with 1350, Predict time samples directly.Mish Activation Function, 2 Second clips. 0.35 lr decay if no Val_loss Dec for 3epochs. TasNet with Resnet LSTM Lipnet. Loss is Si-SNR",
    "project": "av-speech-seperation",
    "heartbeatAt": "2020-01-20T04:41:15.125766"
}
