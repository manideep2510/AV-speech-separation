{
    "root": "/data/AV-speech-separation1",
    "program": "main_tasnet_attention.py",
    "git": {
        "remote": "https://github.com/manideep2510/AV-speech-separation",
        "commit": "cd22e9512289ff3f44cfa6296041f9d7656a2fc4"
    },
    "email": null,
    "startedAt": "2020-01-22T18:13:02.929458",
    "host": "shell0",
    "username": "4014",
    "executable": "/usr/local/bin/python",
    "os": "Linux-4.15.0-46-generic-x86_64-with-Ubuntu-18.04-bionic",
    "python": "3.6.9",
    "gpu": "TITAN Xp",
    "gpu_count": 1,
    "cpu_count": 12,
    "cuda": "10.0.130",
    "args": [
        "-epochs",
        "20",
        "-batch_size",
        "6",
        "-lr",
        "0.0001"
    ],
    "state": "failed",
    "jobType": null,
    "mode": "dryrun",
    "name": "tdavss_Luong_attention_norm",
    "notes": "Luong_attention, Normalize input with 1350, Predict time samples directly.Mish Activation Function, 2 Second clips. 0.35 lr decay if no Val_loss Dec for 3epochs. TasNet with Resnet LSTM Lipnet. Loss is Si-SNR",
    "project": "av-speech-seperation",
    "heartbeatAt": "2020-01-22T18:13:14.736508",
    "exitcode": 1
}
