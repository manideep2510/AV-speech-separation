Training data: 100000
Validation data: 6002
3D Conv Out: (None, 50, 32, 32, 64)
3D Conv Out Reshape: (None, 32, 32, 64)
Resnet18 Out: (None, 1, 1, 512)
Resnet18 Linear Out: (None, 256)
Input to GRU: (None, 50, 256)
GRU Out: (None, 50, 29)
ResNet LSTM Pretrain weights loaded
outv: (None, 200, 256)
outa: (None, 200, 256)
hidden (None, 256)
[TensorShape([None, 200, 256]), TensorShape([None, 256]), TensorShape([])]
Traceback (most recent call last):
  File "main_tasnet_attention.py", line 117, in <module>
    tasnet = TasNet(time_dimensions=200, frequency_bins=257, n_frames=50, attention=True, lipnet_pretrained=True,  train_lipnet=False)
  File "/data/AV-speech-separation1/models/tdavss_attention.py", line 75, in __init__
    self.build()
  File "/data/AV-speech-separation1/models/tdavss_attention.py", line 140, in build
    context_vector, attn_states = attention_layer([self.outa,hidden_state,timestep])
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File "/data/AV-speech-separation1/models/layers.py", line 218, in call
    attention_score = Dot(axes=[2, 2])([weighted_hidden_states, target_hidden_state])       # (B, S*, 1)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 817, in __call__
    self._maybe_build(inputs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 2141, in _maybe_build
    self.build(input_shapes)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py", line 306, in wrapper
    output_shape = fn(instance, input_shape)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/merge.py", line 502, in build
    'Layer shapes: %s, %s' % (shape1, shape2))
ValueError: Dimension incompatibility 256 != None. Layer shapes: (None, 200, 256), (2, 1, None, 256)
