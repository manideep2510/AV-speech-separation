{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from keras import Model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback, ReduceLROnPlateau, EarlyStopping, ReduceLROnPlateau\n",
    "from callbacks import Metrics, learningratescheduler, earlystopping, reducelronplateau\n",
    "from plotting import plot_loss_and_acc\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read the images in numerical order\n",
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(spect1, spect2):\n",
    "    loss = tf.sqrt(tf.nn.l2_loss(spect1[:,:,:,0] - spect2[:,:,:,0]))\n",
    "    #loss = tf.sqrt(tf.nn.l2_loss(spect1 - spect2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LipNet(input_shape, pretrained=None, output_size = 28, absolute_max_string_len=32):\n",
    "        \n",
    "        '''if K.image_data_format() == 'channels_first':\n",
    "            input_shape = (img_c, frames_n, img_w, img_h)\n",
    "        else:\n",
    "            input_shape = (frames_n, img_w, img_h, img_c)'''\n",
    "\n",
    "        input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "\n",
    "        zero1 = ZeroPadding3D(padding=(1, 2, 2), name='zero1')(input_data)\n",
    "        conv1 = Conv3D(32, (3, 5, 5), strides=(1, 2, 2), kernel_initializer='he_normal', name='conv1')(zero1)\n",
    "        batc1 = BatchNormalization(name='batc1')(conv1)\n",
    "        actv1 = Activation('relu', name='actv1')(batc1)\n",
    "        drop1 = SpatialDropout3D(0.5)(actv1)\n",
    "        maxp1 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max1')(drop1)\n",
    "\n",
    "        zero2 = ZeroPadding3D(padding=(1, 2, 2), name='zero2')(maxp1)\n",
    "        conv2 = Conv3D(64, (3, 5, 5), strides=(1, 1, 1), kernel_initializer='he_normal', name='conv2')(zero2)\n",
    "        batc2 = BatchNormalization(name='batc2')(conv2)\n",
    "        actv2 = Activation('relu', name='actv2')(batc2)\n",
    "        drop2 = SpatialDropout3D(0.5)(actv2)\n",
    "        maxp2 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max2')(drop2)\n",
    "\n",
    "        zero3 = ZeroPadding3D(padding=(1, 1, 1), name='zero3')(maxp2)\n",
    "        conv3 = Conv3D(96, (3, 3, 3), strides=(1, 1, 1), kernel_initializer='he_normal', name='conv3')(zero3)\n",
    "        batc3 = BatchNormalization(name='batc3')(conv3)\n",
    "        actv3 = Activation('relu', name='actv3')(batc3)\n",
    "        drop3 = SpatialDropout3D(0.5)(actv3)\n",
    "        maxp3 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max3')(drop3)\n",
    "\n",
    "        resh1 = TimeDistributed(Flatten())(maxp3)\n",
    "\n",
    "        gru_1 = Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru1'), merge_mode='concat')(resh1)\n",
    "        gru_2 = Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru2'), merge_mode='concat')(gru_1)\n",
    "\n",
    "        # transforms RNN output to character activations:\n",
    "        dense1 = Dense(output_size, kernel_initializer='he_normal', name='dense1')(gru_2)\n",
    "\n",
    "        y_pred = Activation('softmax', name='softmax')(dense1)\n",
    "\n",
    "        #labels = Input(name='the_labels', shape=[absolute_max_string_len], dtype='float32')\n",
    "        #input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "        #label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "        #loss_out = CTC('ctc', [y_pred, labels, input_length, label_length])\n",
    "\n",
    "        model = Model(inputs=input_data, outputs=y_pred)\n",
    "        \n",
    "        if pretrained == True:\n",
    "            model.load_weights('/Users/manideepkolla/Downloads/unseen-weights178.h5')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoModel():\n",
    "\n",
    "    def __init__(self, filters,filters_audio, audio_ip_shape, video_ip_shape):\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.filters_audio=filters_audio       \n",
    "        self.audio_ip_shape = audio_ip_shape\n",
    "        self.video_ip_shape = video_ip_shape\n",
    "\n",
    "        self.conv1 = Conv2D(filters = filters, kernel_size = (7), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")\n",
    "        self.bn1 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv2 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")\n",
    "        self.bn2 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv3 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (2,2),\n",
    "                      activation = \"relu\")\n",
    "        self.bn3 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv4 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (4,4),\n",
    "                      activation = \"relu\")\n",
    "        self.bn4 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv5 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (8,8),\n",
    "                      activation = \"relu\")\n",
    "        self.bn5 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv6 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (16,16),\n",
    "                      activation = \"relu\")\n",
    "        self.bn6 = BatchNormalization(axis=-1)\n",
    "    \n",
    "\n",
    "        self.conv7 = Lambda(lambda x : tf.expand_dims(x, axis = -1))\n",
    "\n",
    "        self.conv8 = Lambda(lambda x: tf.image.resize_nearest_neighbor(x, size = (298, x.shape[-2])))\n",
    "        \n",
    "        #self.lipnet_model = LipNet(img_c=self.video_ip_shape[3], img_w=self.video_ip_shape[2], img_h=self.video_ip_shape[1], frames_n=self.video_ip_shape[0], absolute_max_string_len=32, output_size=28).build()\n",
    "\n",
    "    def FullModel(self, lipnet_pretrained):\n",
    "\n",
    "        ip = Input(shape = (self.audio_ip_shape[0], self.audio_ip_shape[1], 2)) #; print(\"input_audio\", ip.shape) \n",
    "        ip_embeddings_1 = Input(shape = (int(self.video_ip_shape[0]), int(self.video_ip_shape[1]),int(self.video_ip_shape[2]), int(self.video_ip_shape[3])))#; print(\"ip video\", ip_embeddings_1.shape)  #[75, 512]\n",
    "        #ip_embeddings_2 = Input(shape = (video_ip_shape[0], video_ip_shape[1])); print(\"ip video\", ip_embeddings_2.shape)  #[75, 512]\n",
    "\n",
    "        ip_magnitude = Lambda(lambda x : x[:,:,:,0],name=\"ip_mag\")(ip)#; print(\"ip_mag \", ip_magnitude.shape)  #takes magnitude from stack[magnitude,phase]\n",
    "        ip_phase = Lambda(lambda x : tf.expand_dims(x[:,:,:,1], axis = -1),name=\"ip_phase\")(ip)#; print(\"ip_phase \", ip_phase.shape)  #takes phase from stack[magnitude,phase]\n",
    "\n",
    "        ip_embeddings_1_expanded = Lambda(lambda x : tf.expand_dims(x, axis = -1))(ip_embeddings_1)\n",
    "        #ip_embeddings_2_expanded = Lambda(lambda x : tf.expand_dims(x, axis = -1))(ip_embeddings_2)\n",
    "\n",
    "        #audio_stream = self.AudioModel(ip)\n",
    "        conv = Conv2D(filters = self.filters_audio, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(ip) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 2, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 2, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 3, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 3, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 3, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio//12, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        audio_stream = BatchNormalization(axis=-1)(conv)\n",
    "        print('audio_stream', audio_stream.shape)\n",
    "\n",
    "        '''stream_1 = self.conv1(ip_embeddings_1)\n",
    "        stream_1 = self.bn1(stream_1)\n",
    "        stream_1 = self.conv2(stream_1)\n",
    "        stream_1 = self.bn2(stream_1)\n",
    "        stream_1 = self.conv3(stream_1)\n",
    "        stream_1 = self.bn3(stream_1)\n",
    "        stream_1 = self.conv4(stream_1)\n",
    "        stream_1 = self.bn4(stream_1)\n",
    "        stream_1 = self.conv5(stream_1)\n",
    "        stream_1 = self.bn5(stream_1)\n",
    "        stream_1 = self.conv6(stream_1)\n",
    "        stream_1 = self.bn6(stream_1)\n",
    "        h,w = stream_1.shape[1], stream_1.shape[2]\n",
    "        c=stream_1.shape[3]\n",
    "        print(h,w,c)\n",
    "        re=Lambda(lambda x: tf.reshape(x,shape=(-1,h*w,c)))(stream_1)\n",
    "        print(re.shape)\n",
    "        stream_2 = self.conv7(re) \n",
    "        video_stream_1 = self.conv8(stream_2)\n",
    "        print(video_stream_1.shape)'''\n",
    "        \n",
    "        #self.lipnet_model.load_weights('/Users/manideepkolla/Downloads/unseen-weights178.h5')\n",
    "        \n",
    "        '''x = self.lipnet_model.layers[-2].output\n",
    "        #x = Model(inputs = ip_embeddings_1, outputs=x).output\n",
    "        x = self.conv7(x)\n",
    "        video_stream_1 = self.conv8(x)\n",
    "        print(video_stream_1.shape)'''\n",
    "        \n",
    "        lipnet_model = LipNet(input_shape = (500,50,100,3), pretrained=lipnet_pretrained)\n",
    "        x = lipnet_model.output\n",
    "        x = Dense(128, kernel_initializer='he_normal', name='dense2')(x)\n",
    "        x = Dense(256, kernel_initializer='he_normal', name='dense3')(x)\n",
    "        x = self.conv7(x)\n",
    "        video_stream_1 = self.conv8(x)\n",
    "\n",
    "#         stream_2 = self.conv1(ip_embeddings_2)\n",
    "#         stream_2 = self.bn1(stream_2)\n",
    "#         stream_2 = self.conv2(stream_2)\n",
    "#         stream_2 = self.bn2(stream_2)\n",
    "#         stream_2 = self.conv3(stream_2)\n",
    "#         stream_2 = self.bn3(stream_2)\n",
    "#         stream_2 = self.conv4(stream_2)\n",
    "#         stream_2 = self.bn4(stream_2)\n",
    "#         stream_2 = self.conv5(stream_2)\n",
    "#         stream_2 = self.bn5(stream_2)\n",
    "#         stream_2 = self.conv6(stream_2)\n",
    "#         stream_2 = self.bn6(stream_2)\n",
    "#         stream_2 = self.conv7(stream_2)\n",
    "#         video_stream_2 = self.conv8(stream_2)\n",
    "\n",
    "        audio_flatten = TimeDistributed(Flatten())(audio_stream) \n",
    "        print(audio_flatten.shape)\n",
    "        video_flatten_1 = TimeDistributed(Flatten())(video_stream_1)\n",
    "        print(video_flatten_1.shape)\n",
    "        #video_flatten_2 = TimeDistributed(Flatten())(video_stream_2)\n",
    "\n",
    "        #print(\"video Streams \", video_stream_1.shape, video_stream_2.shape)\n",
    "        #print(\"Flatten Streams\", video_flatten_1.shape, video_flatten_2.shape, audio_flatten.shape)\n",
    "\n",
    "        concated = concatenate([audio_flatten, video_flatten_1], axis = 2) \n",
    "        print(\"concat shape \", concated.shape)\n",
    "\n",
    "        lstm = Bidirectional(LSTM(units = 64, return_sequences = True, activation = \"tanh\"))(concated)   \n",
    "        #;print(\"lstm\", lstm.shape)\n",
    "\n",
    "        flatten = Flatten()(lstm) \n",
    "        #;print(\"flatten \", flatten.shape)\n",
    "\n",
    "        dense = Dense(100, activation = \"relu\")(flatten)\n",
    "\n",
    "        dense = Dense(2 * self.audio_ip_shape[0] * self.audio_ip_shape[1], activation = \"sigmoid\")(dense) \n",
    "        #;print(\"dense final \",dense.shape)\n",
    "\n",
    "        combo_mask = Reshape([2 , self.audio_ip_shape[0], self.audio_ip_shape[1]])(dense) \n",
    "        #; print(\"combo_mask \", combo_mask.shape)\n",
    "        mask_1 = Lambda(lambda x : x[:,0])(combo_mask) \n",
    "\n",
    "        output_mag_1 = Lambda(lambda x : tf.multiply(x[0], x[1]), name = \"mask_multiply_1\")([ip_magnitude, mask_1])#; print(\"output_mag_1\", output_mag_1.shape)\n",
    "        #output_mag_2 = Lambda(lambda x : tf.multiply(x[0], x[1]), name = \"mask_multiply_2\")([ip_magnitude, mask_2]) ; print(\"output_mag_2\", output_mag_2.shape)\n",
    "\n",
    "        output_mag_1 = Lambda(lambda x : tf.expand_dims(x, axis= -1), name= \"expand_dim_1\")(output_mag_1)#; print(\"output_mag_expand_1\", output_mag_1.shape)\n",
    "        #output_mag_2 = Lambda(lambda x : tf.expand_dims(x, axis= -1), name= \"expand_dim_2\")(output_mag_2) ; print(\"output_mag_expand_2\", output_mag_2.shape)\n",
    "\n",
    "        output_final_1 = Lambda(lambda x : tf.concat(values=[x[0], x[1]], axis = -1),name=\"concat_mag_phase_1\")([output_mag_1, ip_phase]) \n",
    "        #; print(\"output_final_1 \", output_final_1.shape)\n",
    "        #output_final_2 = Lambda(lambda x : tf.concat(values=[x[0], x[1]], axis = -1),name=\"concat_mag_phase_2\")([output_mag_2, ip_phase]) ; print(\"output_final_2 \", output_final_2.shape)\n",
    "\n",
    "        model = Model([ip, lipnet_model.input], [output_final_1])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv  (?, 298, 257, 96)\n",
      "conv  (?, 298, 257, 96)\n",
      "conv  (?, 298, 257, 96)\n",
      "conv  (?, 298, 257, 192)\n",
      "conv  (?, 298, 257, 192)\n",
      "conv  (?, 298, 257, 288)\n",
      "conv  (?, 298, 257, 288)\n",
      "conv  (?, 298, 257, 288)\n",
      "conv  (?, 298, 257, 8)\n",
      "audio_stream (?, 298, 257, 8)\n",
      "(?, 298, 2056)\n",
      "(?, 298, 256)\n",
      "concat shape  (?, 298, 2312)\n"
     ]
    }
   ],
   "source": [
    "model = VideoModel(256,96,(298,257,2),(500,50,100,3)).FullModel(lipnet_pretrained = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "lrate = 0.0001\n",
    "model.compile(optimizer = Adam(lr=lrate), loss = l2_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_list = sorted(glob.glob('/Users/manideepkolla/Downloads/test_fold/output/*'), key=numericalSort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataGenerator \n",
    "\n",
    "def DataGenerator(lips_filelist, masks_filelist, spects_filelist, batch_size):\n",
    "\n",
    "    L = len(files)\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that\n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            \n",
    "            X_lips = np.asarray([get_video_frames(fname) for fname in lips_filelist[batch_start:limit]])\n",
    "            \n",
    "            X_mask = np.asarray([np.load(fname) for fname in masks_filelist[batch_start:limit]])\n",
    "            \n",
    "            X_spect = np.asarray([np.load(fname) for fname in spects_filelist[batch_start:limit]])\n",
    "            \n",
    "            spect_len = X_spect.shape[1]\n",
    "            mask_len = X_mask.shape[1]\n",
    "            fps = 25\n",
    "            frames_10s = fps*10\n",
    "            frames = X_lips.shape[0]\n",
    "            \n",
    "            # Pad or crop spectrogram to 10 seconds\n",
    "            if spect_len > 1000:\n",
    "                X_spect = X_spect[:, :1000]\n",
    "                \n",
    "            elif spect_len < 1000:\n",
    "                pad_len = 1000 - spect_len\n",
    "                X_spect = np.pad(X_spect, ((0,0),(0,pad_len)), 'constant')\n",
    "                \n",
    "            elif spect_len == 1000:\n",
    "                X_spect = X_spect\n",
    "                \n",
    "            # Pad or crop mask to 10 seconds\n",
    "            if mask_len > 1000:\n",
    "                X_mask = X_mask[:, :1000]\n",
    "                \n",
    "            elif mask_len < 1000:\n",
    "                pad_len = 1000 - mask_len\n",
    "                X_mask = np.pad(X_mask, ((0,0),(0,pad_len)), 'constant')\n",
    "                \n",
    "            elif mask_len == 1000:\n",
    "                X_mask = X_mask\n",
    "                \n",
    "            # Delete or add frames to make the video to 10 seconds\n",
    "            if frames > frames_10s:\n",
    "                X_lips = X_lips[:frames_10s, :, :, :]\n",
    "                \n",
    "            elif frames < 1000:\n",
    "                pad_len = frames_10s - frames\n",
    "                X_lips = np.pad(X_lips, ((0,pad_len),(0,0), (0,0), (0,0)), 'constant')\n",
    "                \n",
    "            elif frames == 1000:\n",
    "                X_lips = X_lips\n",
    "            \n",
    "            #X = seq.augment_images(X)\n",
    "            \n",
    "            yield X_lips, X_spect, X_mask\n",
    "\n",
    "            batch_start += batch_size\n",
    "            batch_end += batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callcack\n",
    "metrics = Metrics()\n",
    "learningratescheduler = learningratescheduler()\n",
    "earlystopping = earlystopping()\n",
    "reducelronplateau = reducelronplateau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save model checkpoints\n",
    "\n",
    "path = ''\n",
    "\n",
    "try:\n",
    "    os.mkdir('/home/manideep/models/'+ path)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "filepath='/home/manideep/models/' +  path+ '/weights-best.hdf5'\n",
    "checkpoint_save_weights = ModelCheckpoint(filepath, monitor='val_acc', save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Generator\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "history = model.fit_generator(DataGenerator(lips_filelist, masks_filelist, spects_filelist, batch_size),\n",
    "                steps_per_epoch = np.ceil((len(lips_filelist)/float(batch_size)),\n",
    "                epochs=epochs,\n",
    "                validation_data=DataGenerator(lips_filelist_val, masks_filelist_val, spects_filelist_val, batch_size), \n",
    "                validation_steps = np.ceil((len(lips_filelist_val)/float(batch_size)),\n",
    "                callbacks=[earlystopping, learningratescheduler, checkpoint_save_weights], verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sorted(glob.glob('/Users/manideepkolla/Downloads/lrs2/mvlrs_v1/*/*/*.mp4'), key=numericalSort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import sys\n",
    "sys.path.append('/Users/manideepkolla/av-speech-separation/LipNet')\n",
    "sys.path.append('/Users/manideepkolla/av-speech-separation/models')\n",
    "sys.path.append('/Users/manideepkolla/av-speech-separation/models/classification_models-master/')\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "from models.sep_resnet_lstm_lipread import lipreading\n",
    "from models.attention_layers import AttentionLayer, multi_head_self_attention\n",
    "from models.mish import Mish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_Block(inputs,dialation_rate=1,stride=1,filters=512,kernel_size=3):\n",
    "    \n",
    "    x = Conv1D(filters,1)(inputs)\n",
    "    #x = Mish('Mish')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x= GlobalLayerNorm()(x)\n",
    "    x = SeparableConv1D(filters,kernel_size,dilation_rate=dialation_rate,padding='same',strides=stride)(x)\n",
    "    #x = Mish('Mish')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x= GlobalLayerNorm()(x)\n",
    "    x = Conv1D(int(inputs.shape[-1]),1)(x)\n",
    "    x = Add()([inputs,x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def Conv_Block_Audio(inputs,dialation_rate=1,stride=1,filters=512,kernel_size=3):\n",
    "    \n",
    "    x = Conv1D(filters,1)(inputs)\n",
    "    #x = Mish('Mish')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x= GlobalLayerNorm()(x)\n",
    "    x = SeparableConv1D(filters,kernel_size,dilation_rate=dialation_rate,padding='same',strides=stride)(x)\n",
    "    x = Add()([inputs,x])\n",
    "    \n",
    "    return x\n",
    "\n",
    "def Conv_Block_Video(inputs,dialation_rate=1,stride=1,filters=512,kernel_size=3):\n",
    "    \n",
    "    \n",
    "    #x = Mish('Mish')(inputs)\n",
    "    x = Activation('relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SeparableConv1D(filters,kernel_size,dilation_rate=dialation_rate,padding='same',strides=stride)(x)\n",
    "    x = Add()([inputs,x])\n",
    "    \n",
    "    return x\n",
    "\n",
    "def vec_l2norm(x):\n",
    "\n",
    "    nr = K.sqrt(tf.math.reduce_sum(K.square(x), axis=1))\n",
    "    nr = tf.reshape(nr, (-1, 1, 1))\n",
    "    #nr = tf.broadcast_to(nr, (int(x.shape[1]), int(x.shape[0])))\n",
    "    return nr\n",
    "\n",
    "class GlobalLayerNorm(Layer):\n",
    "    \"\"\"Global Layer Normalization (gLN)\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        super(GlobalLayerNorm, self).__init__(**kwargs)\n",
    "      \n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        self.gamma = self.add_weight(name='gamma',shape=(1,1,input_shape[2]),initializer='Ones',trainable='True')\n",
    "        self.beta = self.add_weight(name='beta',shape=(1,1,input_shape[2]),initializer='Zeros',trainable='True')\n",
    "        super(GlobalLayerNorm, self).build(input_shape)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        mean = tf.math.reduce_mean((tf.math.reduce_mean(inputs,axis=2,keepdims=True)),axis=1,keepdims=True)\n",
    "        var = tf.math.square((inputs-mean))\n",
    "        var = tf.math.reduce_mean((tf.math.reduce_mean(var,axis=2,keepdims=True)),axis=1,keepdims=True)\n",
    "        gln = self.gamma*(inputs-mean)*tf.math.rsqrt(var+1e-8)+self.beta\n",
    "        return gln\n",
    "\n",
    "class ChannelwiseLayerNorm(Layer):\n",
    "    \"\"\"Channel-wise Layer Normalization (cLN)\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        super(ChannelwiseLayerNorm, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        self.gamma=self.add_weight(name='gamma',shape=(1,1,input_shape[2]),initializer='Ones',trainable='True')\n",
    "        self.beta=self.add_weight(name='beta',shape=(1,1,input_shape[2]),initializer='Zeros',trainable='True')\n",
    "        super(ChannelwiseLayerNorm, self).build(input_shape)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        mean = tf.math.reduce_mean(inputs,axis=2,keepdims=True)\n",
    "        var = tf.math.square(tf.math.reduce_std(inputs,axis=2,keepdims=True))\n",
    "        cln = self.gamma*(inputs-mean)*tf.math.rsqrt(var+1e-8)+self.beta\n",
    "        return cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TasNet(object):\n",
    "    \n",
    "    def __init__(self,time_dimensions=500,frequency_bins=257,n_frames=125, attention=None, lstm = False,lipnet_pretrained=None, train_lipnet=None):\n",
    "        \n",
    "        self.t=time_dimensions\n",
    "        self.f=frequency_bins\n",
    "        self.frames=n_frames\n",
    "        self.lipnet_pretrained = lipnet_pretrained\n",
    "        self.train_lipnet = train_lipnet\n",
    "        self.attention = attention\n",
    "        self.lstm = lstm\n",
    "        #self.positions=self.GetPosEncodingMatrix(self.t,512)\n",
    "        self.build()\n",
    "    \n",
    "    '''def GetPosEncodingMatrix(self,max_len, d_emb):\n",
    "        pos_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)]\n",
    "        if pos != 0 else np.zeros(d_emb)\n",
    "            for pos in range(max_len)\n",
    "            ])\n",
    "        pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "        pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "        return pos_enc'''\n",
    "\n",
    "    def build(self):\n",
    "        \n",
    "        \n",
    "        #self.video_input_data=Input(shape=(self.frames,))#video_shape=(125,256)\n",
    "        self.audio_input_data=Input(shape=(self.t*160,1))#audio_shape=(80000,1)\n",
    "\n",
    "        '''self.norm = vec_l2norm(self.audio_input_data)\n",
    "        self.audio_normalized = self.audio_input_data/self.norm'''\n",
    "        \n",
    "        #audio_encoding\n",
    "        self.audio=Conv1D(256,40,padding='same',strides=20, activation='relu')(self.audio_input_data)\n",
    "        #self.audio=Conv1D(256,16,padding='same',strides=8, activation='relu')(self.audio)\n",
    "        self.audio = ChannelwiseLayerNorm()(self.audio)\n",
    "        \n",
    "        #video_processing\n",
    "\n",
    "        self.lipnet_model = lipreading(mode='backendGRU', inputDim=256, hiddenDim=512, nClasses=29, frameLen=self.frames, AbsoluteMaxStringLen=128, every_frame=True, pretrain=self.lipnet_pretrained)\n",
    "\n",
    "        if self.train_lipnet == False:\n",
    "            for layer in self.lipnet_model.layers:\n",
    "                layer.trainable = False\n",
    "\n",
    "        if self.lstm == True:\n",
    "            self.outv = self.lipnet_model.output\n",
    "            self.outv = Dense(128, kernel_initializer='he_normal', name='dense2')(self.outv)\n",
    "            self.outv = Dense(256, kernel_initializer='he_normal', name='dense3')(self.outv)\n",
    "            #self.outv = GlobalAveragePooling2D(self.outv)\n",
    "        else:\n",
    "            self.outv = self.lipnet_model.layers[-4].output\n",
    "        \n",
    "        #video_processing\n",
    "        self.video_data=Conv1D(512,1)(self.outv)\n",
    "        self.outv=Conv_Block_Video(self.video_data)\n",
    "        self.outv=Conv_Block_Video(self.outv)\n",
    "        self.outv=Conv_Block_Video(self.outv)\n",
    "        self.outv=Conv_Block_Video(self.outv)\n",
    "        self.outv=Conv_Block_Video(self.outv)\n",
    "        self.outv=Conv1D(256,1)(self.outv)\n",
    "        \n",
    "        #audio_processing\n",
    "        self.outa=Conv_Block(self.audio,dialation_rate=1)\n",
    "        self.outa=Conv_Block(self.outa,dialation_rate=2)\n",
    "        self.outa=Conv_Block(self.outa,dialation_rate=4)\n",
    "        self.outa=Conv_Block(self.outa,dialation_rate=8)\n",
    "        self.outa=Conv_Block(self.outa,dialation_rate=16)\n",
    "        self.outa=Conv_Block(self.outa,dialation_rate=32)\n",
    "        self.outa=Conv_Block(self.outa,dialation_rate=64)\n",
    "        self.outa=Conv_Block(self.outa,dialation_rate=128)\n",
    "        \n",
    "        #fusion_process\n",
    "        \n",
    "        self.outv=UpSampling1D(size=4*8)(self.outv)\n",
    "\n",
    "        print('outv:', self.outv.shape)\n",
    "        print('outa:', self.outa.shape)\n",
    "\n",
    "        if self.attention == True:\n",
    "            #self.outa1=Conv1D(256,16,padding='same',strides=8, activation='relu')(self.outa)\n",
    "            self.attn_layer = AttentionLayer(name='attention_layer')\n",
    "            self.attn_out, self.attn_states = self.attn_layer([self.outv, self.outa], verbose=False)\n",
    "            print('attn_out:', self.attn_out.shape)\n",
    "            print('attn_states:', self.attn_states.shape)\n",
    "\n",
    "            \n",
    "            self.fusion=concatenate([self.attn_out, self.outv, self.outa],axis=-1)  # B, 200, 512\n",
    "            #self.fusion = Conv1D(512, 1)(self.fusion)\n",
    "            #self.fusion = Lambda(lambda x: K.expand_dims(x, axis=2))(self.fusion)\n",
    "            #self.fusion=Conv2DTranspose(256,(16,1),strides=(8,1),padding='same',data_format='channels_last')(self.fusion) # B, 1600, 256\n",
    "            #self.fusion = Lambda(lambda x: K.squeeze(x, axis=2), name='fusion_out')(self.fusion)\n",
    "            \n",
    "            #self.fusion=concatenate([self.fusion, self.outa],axis=-1)  # B, 200, 512\n",
    "            self.fusion=Conv1D(512,1)(self.fusion)\n",
    "        else:\n",
    "            self.fusion=concatenate([self.outv,self.outa],axis=-1)\n",
    "        \n",
    "        print('fusion:', self.fusion.shape)\n",
    "\n",
    "        '''self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        print('self attention fusion shape',self.fusion.shape)'''\n",
    "\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=1,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=2,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=4,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=8,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=16,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=32,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=64,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=128,filters=512)\n",
    "\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=1,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=2,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=4,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=8,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=16,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=32,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=64,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=128,filters=512)\n",
    "\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=1,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=2,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=4,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=8,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=16,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=32,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=64,filters=512)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=128,filters=512)\n",
    "        \n",
    "        #Decoding\n",
    "        self.mask=Conv1D(256,1,activation='relu', name='mask')(self.fusion)\n",
    "        #self.mask = Activation('relu')(self.fusion)\n",
    "        self.fusion=Multiply()([self.audio,self.mask])\n",
    "        self.decode = Lambda(lambda x: K.expand_dims(x, axis=2))(self.fusion)\n",
    "\n",
    "        #self.decode=Conv2DTranspose(256,(16,1),strides=(8,1),padding='same',data_format='channels_last')(self.decode)\n",
    "        self.decode=Conv2DTranspose(1,(40,1),strides=(20,1),padding='same',data_format='channels_last')(self.decode)\n",
    "        self.out = Lambda(lambda x: K.squeeze(x, axis=2), name='out')(self.decode)\n",
    "        print('Out:', self.out.shape)\n",
    "        \n",
    "        '''self.out_norm = vec_l2norm(self.out)\n",
    "        self.out_normalized = self.out/self.out_norm\n",
    "        self.out_denormalized = self.out_normalized*self.norm'''\n",
    "        \n",
    "        self.model=Model(inputs=[self.lipnet_model.input,self.audio_input_data],outputs=[self.out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Conv Out: (None, 50, 32, 32, 64)\n",
      "3D Conv Out Reshape: (None, 32, 32, 64)\n",
      "Resnet18 Out: (None, 1, 1, 512)\n",
      "Resnet18 Linear Out: (None, 256)\n",
      "Input to GRU: (None, 50, 256)\n",
      "GRU Out: (None, 50, 29)\n",
      "outv: (None, 1600, 256)\n",
      "outa: (None, 1600, 256)\n",
      "fusion: (None, 1600, 512)\n",
      "Out: (None, 32000, 1)\n"
     ]
    }
   ],
   "source": [
    "tasnet = TasNet(time_dimensions=200, frequency_bins=257, n_frames=50,\n",
    "                      attention=False, lstm=False, lipnet_pretrained=False,  train_lipnet=True)\n",
    "model = tasnet.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 32000, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_241 (Conv1D)             (None, 1600, 256)    10496       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "channelwise_layer_norm_8 (Chann (None, 1600, 256)    512         conv1d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_246 (Conv1D)             (None, 1600, 512)    131584      channelwise_layer_norm_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 1600, 512)    0           conv1d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 1600, 512)    2048        activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_202 (Separable (None, 1600, 512)    264192      batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 1600, 512)    0           separable_conv1d_202[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 1600, 512)    2048        activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_247 (Conv1D)             (None, 1600, 256)    131328      batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_274 (Add)                   (None, 1600, 256)    0           channelwise_layer_norm_8[0][0]   \n",
      "                                                                 conv1d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_248 (Conv1D)             (None, 1600, 512)    131584      add_274[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 1600, 512)    0           conv1d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 1600, 512)    2048        activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_203 (Separable (None, 1600, 512)    264192      batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 1600, 512)    0           separable_conv1d_203[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 1600, 512)    2048        activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_249 (Conv1D)             (None, 1600, 256)    131328      batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_275 (Add)                   (None, 1600, 256)    0           add_274[0][0]                    \n",
      "                                                                 conv1d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_250 (Conv1D)             (None, 1600, 512)    131584      add_275[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 1600, 512)    0           conv1d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 1600, 512)    2048        activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_204 (Separable (None, 1600, 512)    264192      batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 1600, 512)    0           separable_conv1d_204[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 1600, 512)    2048        activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_251 (Conv1D)             (None, 1600, 256)    131328      batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_276 (Add)                   (None, 1600, 256)    0           add_275[0][0]                    \n",
      "                                                                 conv1d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_252 (Conv1D)             (None, 1600, 512)    131584      add_276[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 1600, 512)    0           conv1d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 1600, 512)    2048        activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_205 (Separable (None, 1600, 512)    264192      batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 1600, 512)    0           separable_conv1d_205[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 1600, 512)    2048        activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_253 (Conv1D)             (None, 1600, 256)    131328      batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_277 (Add)                   (None, 1600, 256)    0           add_276[0][0]                    \n",
      "                                                                 conv1d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_254 (Conv1D)             (None, 1600, 512)    131584      add_277[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "frames_input (InputLayer)       [(None, 50, 50, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 1600, 512)    0           conv1d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sequential_24 (Sequential)      (None, 50, 32, 32, 6 15936       frames_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 1600, 512)    2048        activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda2 (Lambda)                (None, 32, 32, 64)   0           sequential_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_206 (Separable (None, 1600, 512)    264192      batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "model_20 (Model)                multiple             1451072     lambda2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 1600, 512)    0           separable_conv1d_206[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_avgpool_resnet (GlobalAv (None, 512)          0           model_20[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 1600, 512)    2048        activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_resnet (Dense)            (None, 256)          131328      global_avgpool_resnet[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_255 (Conv1D)             (None, 1600, 256)    131328      batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "bn_resnet (BatchNormalization)  (None, 256)          1024        dense_resnet[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_278 (Add)                   (None, 1600, 256)    0           add_277[0][0]                    \n",
      "                                                                 conv1d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda6 (Lambda)                (None, 50, 256)      0           bn_resnet[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_256 (Conv1D)             (None, 1600, 512)    131584      add_278[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_244 (Conv1D)             (None, 50, 512)      131584      lambda6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 1600, 512)    0           conv1d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 50, 512)      0           conv1d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 1600, 512)    2048        activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 50, 512)      2048        activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_207 (Separable (None, 1600, 512)    264192      batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_197 (Separable (None, 50, 512)      264192      batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 1600, 512)    0           separable_conv1d_207[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_269 (Add)                   (None, 50, 512)      0           conv1d_244[0][0]                 \n",
      "                                                                 separable_conv1d_197[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 1600, 512)    2048        activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 50, 512)      0           add_269[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_257 (Conv1D)             (None, 1600, 256)    131328      batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 50, 512)      2048        activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_279 (Add)                   (None, 1600, 256)    0           add_278[0][0]                    \n",
      "                                                                 conv1d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_198 (Separable (None, 50, 512)      264192      batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_258 (Conv1D)             (None, 1600, 512)    131584      add_279[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_270 (Add)                   (None, 50, 512)      0           add_269[0][0]                    \n",
      "                                                                 separable_conv1d_198[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 1600, 512)    0           conv1d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 50, 512)      0           add_270[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 1600, 512)    2048        activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 50, 512)      2048        activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_208 (Separable (None, 1600, 512)    264192      batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_199 (Separable (None, 50, 512)      264192      batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 1600, 512)    0           separable_conv1d_208[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_271 (Add)                   (None, 50, 512)      0           add_270[0][0]                    \n",
      "                                                                 separable_conv1d_199[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 1600, 512)    2048        activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 50, 512)      0           add_271[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_259 (Conv1D)             (None, 1600, 256)    131328      batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 50, 512)      2048        activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_280 (Add)                   (None, 1600, 256)    0           add_279[0][0]                    \n",
      "                                                                 conv1d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_200 (Separable (None, 50, 512)      264192      batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_260 (Conv1D)             (None, 1600, 512)    131584      add_280[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_272 (Add)                   (None, 50, 512)      0           add_271[0][0]                    \n",
      "                                                                 separable_conv1d_200[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 1600, 512)    0           conv1d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 50, 512)      0           add_272[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 1600, 512)    2048        activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 50, 512)      2048        activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_209 (Separable (None, 1600, 512)    264192      batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_201 (Separable (None, 50, 512)      264192      batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 1600, 512)    0           separable_conv1d_209[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_273 (Add)                   (None, 50, 512)      0           add_272[0][0]                    \n",
      "                                                                 separable_conv1d_201[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 1600, 512)    2048        activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_245 (Conv1D)             (None, 50, 256)      131328      add_273[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_261 (Conv1D)             (None, 1600, 256)    131328      batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1D)  (None, 1600, 256)    0           conv1d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_281 (Add)                   (None, 1600, 256)    0           add_280[0][0]                    \n",
      "                                                                 conv1d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1600, 512)    0           up_sampling1d_5[0][0]            \n",
      "                                                                 add_281[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_262 (Conv1D)             (None, 1600, 512)    262656      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 1600, 512)    0           conv1d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_122 (GlobalLa (None, 1600, 512)    1024        activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_210 (Separable (None, 1600, 512)    264192      global_layer_norm_122[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_282 (Add)                   (None, 1600, 512)    0           concatenate_5[0][0]              \n",
      "                                                                 separable_conv1d_210[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_263 (Conv1D)             (None, 1600, 512)    262656      add_282[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 1600, 512)    0           conv1d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_123 (GlobalLa (None, 1600, 512)    1024        activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_211 (Separable (None, 1600, 512)    264192      global_layer_norm_123[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_283 (Add)                   (None, 1600, 512)    0           add_282[0][0]                    \n",
      "                                                                 separable_conv1d_211[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_264 (Conv1D)             (None, 1600, 512)    262656      add_283[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 1600, 512)    0           conv1d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_124 (GlobalLa (None, 1600, 512)    1024        activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_212 (Separable (None, 1600, 512)    264192      global_layer_norm_124[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_284 (Add)                   (None, 1600, 512)    0           add_283[0][0]                    \n",
      "                                                                 separable_conv1d_212[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_265 (Conv1D)             (None, 1600, 512)    262656      add_284[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 1600, 512)    0           conv1d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_125 (GlobalLa (None, 1600, 512)    1024        activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_213 (Separable (None, 1600, 512)    264192      global_layer_norm_125[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_285 (Add)                   (None, 1600, 512)    0           add_284[0][0]                    \n",
      "                                                                 separable_conv1d_213[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_266 (Conv1D)             (None, 1600, 512)    262656      add_285[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 1600, 512)    0           conv1d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_126 (GlobalLa (None, 1600, 512)    1024        activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_214 (Separable (None, 1600, 512)    264192      global_layer_norm_126[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_286 (Add)                   (None, 1600, 512)    0           add_285[0][0]                    \n",
      "                                                                 separable_conv1d_214[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_267 (Conv1D)             (None, 1600, 512)    262656      add_286[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 1600, 512)    0           conv1d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_127 (GlobalLa (None, 1600, 512)    1024        activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_215 (Separable (None, 1600, 512)    264192      global_layer_norm_127[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_287 (Add)                   (None, 1600, 512)    0           add_286[0][0]                    \n",
      "                                                                 separable_conv1d_215[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_268 (Conv1D)             (None, 1600, 512)    262656      add_287[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 1600, 512)    0           conv1d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_128 (GlobalLa (None, 1600, 512)    1024        activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_216 (Separable (None, 1600, 512)    264192      global_layer_norm_128[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_288 (Add)                   (None, 1600, 512)    0           add_287[0][0]                    \n",
      "                                                                 separable_conv1d_216[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_269 (Conv1D)             (None, 1600, 512)    262656      add_288[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 1600, 512)    0           conv1d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_129 (GlobalLa (None, 1600, 512)    1024        activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_217 (Separable (None, 1600, 512)    264192      global_layer_norm_129[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_289 (Add)                   (None, 1600, 512)    0           add_288[0][0]                    \n",
      "                                                                 separable_conv1d_217[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_270 (Conv1D)             (None, 1600, 512)    262656      add_289[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 1600, 512)    0           conv1d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_130 (GlobalLa (None, 1600, 512)    1024        activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_218 (Separable (None, 1600, 512)    264192      global_layer_norm_130[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_290 (Add)                   (None, 1600, 512)    0           add_289[0][0]                    \n",
      "                                                                 separable_conv1d_218[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_271 (Conv1D)             (None, 1600, 512)    262656      add_290[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 1600, 512)    0           conv1d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_131 (GlobalLa (None, 1600, 512)    1024        activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_219 (Separable (None, 1600, 512)    264192      global_layer_norm_131[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_291 (Add)                   (None, 1600, 512)    0           add_290[0][0]                    \n",
      "                                                                 separable_conv1d_219[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_272 (Conv1D)             (None, 1600, 512)    262656      add_291[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 1600, 512)    0           conv1d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_132 (GlobalLa (None, 1600, 512)    1024        activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_220 (Separable (None, 1600, 512)    264192      global_layer_norm_132[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_292 (Add)                   (None, 1600, 512)    0           add_291[0][0]                    \n",
      "                                                                 separable_conv1d_220[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_273 (Conv1D)             (None, 1600, 512)    262656      add_292[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 1600, 512)    0           conv1d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_133 (GlobalLa (None, 1600, 512)    1024        activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_221 (Separable (None, 1600, 512)    264192      global_layer_norm_133[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_293 (Add)                   (None, 1600, 512)    0           add_292[0][0]                    \n",
      "                                                                 separable_conv1d_221[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_274 (Conv1D)             (None, 1600, 512)    262656      add_293[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 1600, 512)    0           conv1d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_134 (GlobalLa (None, 1600, 512)    1024        activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_222 (Separable (None, 1600, 512)    264192      global_layer_norm_134[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_294 (Add)                   (None, 1600, 512)    0           add_293[0][0]                    \n",
      "                                                                 separable_conv1d_222[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_275 (Conv1D)             (None, 1600, 512)    262656      add_294[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 1600, 512)    0           conv1d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_135 (GlobalLa (None, 1600, 512)    1024        activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_223 (Separable (None, 1600, 512)    264192      global_layer_norm_135[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_295 (Add)                   (None, 1600, 512)    0           add_294[0][0]                    \n",
      "                                                                 separable_conv1d_223[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_276 (Conv1D)             (None, 1600, 512)    262656      add_295[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 1600, 512)    0           conv1d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_136 (GlobalLa (None, 1600, 512)    1024        activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_224 (Separable (None, 1600, 512)    264192      global_layer_norm_136[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_296 (Add)                   (None, 1600, 512)    0           add_295[0][0]                    \n",
      "                                                                 separable_conv1d_224[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_277 (Conv1D)             (None, 1600, 512)    262656      add_296[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 1600, 512)    0           conv1d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_137 (GlobalLa (None, 1600, 512)    1024        activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_225 (Separable (None, 1600, 512)    264192      global_layer_norm_137[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_297 (Add)                   (None, 1600, 512)    0           add_296[0][0]                    \n",
      "                                                                 separable_conv1d_225[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_278 (Conv1D)             (None, 1600, 512)    262656      add_297[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 1600, 512)    0           conv1d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_138 (GlobalLa (None, 1600, 512)    1024        activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_226 (Separable (None, 1600, 512)    264192      global_layer_norm_138[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_298 (Add)                   (None, 1600, 512)    0           add_297[0][0]                    \n",
      "                                                                 separable_conv1d_226[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_279 (Conv1D)             (None, 1600, 512)    262656      add_298[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 1600, 512)    0           conv1d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_139 (GlobalLa (None, 1600, 512)    1024        activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_227 (Separable (None, 1600, 512)    264192      global_layer_norm_139[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_299 (Add)                   (None, 1600, 512)    0           add_298[0][0]                    \n",
      "                                                                 separable_conv1d_227[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_280 (Conv1D)             (None, 1600, 512)    262656      add_299[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 1600, 512)    0           conv1d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_140 (GlobalLa (None, 1600, 512)    1024        activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_228 (Separable (None, 1600, 512)    264192      global_layer_norm_140[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_300 (Add)                   (None, 1600, 512)    0           add_299[0][0]                    \n",
      "                                                                 separable_conv1d_228[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_281 (Conv1D)             (None, 1600, 512)    262656      add_300[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 1600, 512)    0           conv1d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_141 (GlobalLa (None, 1600, 512)    1024        activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_229 (Separable (None, 1600, 512)    264192      global_layer_norm_141[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_301 (Add)                   (None, 1600, 512)    0           add_300[0][0]                    \n",
      "                                                                 separable_conv1d_229[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_282 (Conv1D)             (None, 1600, 512)    262656      add_301[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 1600, 512)    0           conv1d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_142 (GlobalLa (None, 1600, 512)    1024        activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_230 (Separable (None, 1600, 512)    264192      global_layer_norm_142[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_302 (Add)                   (None, 1600, 512)    0           add_301[0][0]                    \n",
      "                                                                 separable_conv1d_230[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_283 (Conv1D)             (None, 1600, 512)    262656      add_302[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 1600, 512)    0           conv1d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_143 (GlobalLa (None, 1600, 512)    1024        activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_231 (Separable (None, 1600, 512)    264192      global_layer_norm_143[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_303 (Add)                   (None, 1600, 512)    0           add_302[0][0]                    \n",
      "                                                                 separable_conv1d_231[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_284 (Conv1D)             (None, 1600, 512)    262656      add_303[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 1600, 512)    0           conv1d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_144 (GlobalLa (None, 1600, 512)    1024        activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_232 (Separable (None, 1600, 512)    264192      global_layer_norm_144[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_304 (Add)                   (None, 1600, 512)    0           add_303[0][0]                    \n",
      "                                                                 separable_conv1d_232[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_285 (Conv1D)             (None, 1600, 512)    262656      add_304[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 1600, 512)    0           conv1d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_145 (GlobalLa (None, 1600, 512)    1024        activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_233 (Separable (None, 1600, 512)    264192      global_layer_norm_145[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_305 (Add)                   (None, 1600, 512)    0           add_304[0][0]                    \n",
      "                                                                 separable_conv1d_233[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mask (Conv1D)                   (None, 1600, 256)    131328      add_305[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 1600, 256)    0           channelwise_layer_norm_8[0][0]   \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1600, 1, 256) 0           multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32000, 1, 1)  10241       lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out (Lambda)                    (None, 32000, 1)     0           conv2d_transpose_4[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 20,264,577\n",
      "Trainable params: 20,234,369\n",
      "Non-trainable params: 30,208\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TasNet(object):\n",
    "    \n",
    "    def __init__(self,time_dimensions=500,frequency_bins=257,n_frames=125, attention=None, lstm = False,lipnet_pretrained=None, train_lipnet=None):\n",
    "        \n",
    "        self.t=time_dimensions\n",
    "        self.f=frequency_bins\n",
    "        self.frames=n_frames\n",
    "        self.lipnet_pretrained = lipnet_pretrained\n",
    "        self.train_lipnet = train_lipnet\n",
    "        self.attention = attention\n",
    "        self.lstm = lstm\n",
    "        #self.positions=self.GetPosEncodingMatrix(self.t,512)\n",
    "        self.build()\n",
    "    \n",
    "    '''def GetPosEncodingMatrix(self,max_len, d_emb):\n",
    "        pos_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)]\n",
    "        if pos != 0 else np.zeros(d_emb)\n",
    "            for pos in range(max_len)\n",
    "            ])\n",
    "        pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "        pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "        return pos_enc'''\n",
    "\n",
    "    def build(self):\n",
    "        \n",
    "        \n",
    "        #self.video_input_data=Input(shape=(self.frames,))#video_shape=(125,256)\n",
    "        self.audio_input_data=Input(shape=(self.t*160,1))#audio_shape=(80000,1)\n",
    "\n",
    "        '''self.norm = vec_l2norm(self.audio_input_data)\n",
    "        self.audio_normalized = self.audio_input_data/self.norm'''\n",
    "        \n",
    "        #audio_encoding\n",
    "        self.audio=Conv1D(256,40,padding='same',strides=20, activation='relu')(self.audio_input_data)\n",
    "        #self.audio=Conv1D(256,16,padding='same',strides=8, activation='relu')(self.audio)\n",
    "        self.audio = ChannelwiseLayerNorm()(self.audio)\n",
    "        \n",
    "        #video_processing\n",
    "\n",
    "        self.lipnet_model = lipreading(mode='backendGRU', inputDim=256, hiddenDim=512, nClasses=29, frameLen=self.frames, AbsoluteMaxStringLen=128, every_frame=True, pretrain=self.lipnet_pretrained)\n",
    "\n",
    "        if self.train_lipnet == False:\n",
    "            for layer in self.lipnet_model.layers:\n",
    "                layer.trainable = False\n",
    "\n",
    "        if self.lstm == True:\n",
    "            self.outv = self.lipnet_model.output\n",
    "            self.outv = Dense(128, kernel_initializer='he_normal', name='dense2')(self.outv)\n",
    "            self.outv = Dense(256, kernel_initializer='he_normal', name='dense3')(self.outv)\n",
    "            #self.outv = GlobalAveragePooling2D(self.outv)\n",
    "        else:\n",
    "            self.outv = self.lipnet_model.layers[-4].output\n",
    "        \n",
    "        #video_processing\n",
    "        self.video_data=Conv1D(512,1)(self.outv)\n",
    "        self.outv=Conv_Block_Video(self.video_data)\n",
    "        self.outv=Conv_Block_Video(self.outv)\n",
    "        self.outv=Conv_Block_Video(self.outv)\n",
    "        self.outv=Conv_Block_Video(self.outv)\n",
    "        self.outv=Conv_Block_Video(self.outv)\n",
    "        self.outv=Conv1D(256,1)(self.outv)\n",
    "        \n",
    "        #audio_processing\n",
    "        self.outa=Conv_Block_Audio(self.audio,dialation_rate=1,filters=256)\n",
    "        self.outa=Conv_Block_Audio(self.outa,dialation_rate=2,filters=256)\n",
    "        self.outa=Conv_Block_Audio(self.outa,dialation_rate=4,filters=256)\n",
    "        self.outa=Conv_Block_Audio(self.outa,dialation_rate=8,filters=256)\n",
    "        self.outa=Conv_Block_Audio(self.outa,dialation_rate=16,filters=256)\n",
    "        self.outa=Conv_Block_Audio(self.outa,dialation_rate=32,filters=256)\n",
    "        self.outa=Conv_Block_Audio(self.outa,dialation_rate=64,filters=256)\n",
    "        self.outa=Conv_Block_Audio(self.outa,dialation_rate=128,filters=256)\n",
    "        \n",
    "        #fusion_process\n",
    "        \n",
    "        self.outv=UpSampling1D(size=4*8)(self.outv)\n",
    "\n",
    "        print('outv:', self.outv.shape)\n",
    "        print('outa:', self.outa.shape)\n",
    "\n",
    "        if self.attention == True:\n",
    "            #self.outa1=Conv1D(256,16,padding='same',strides=8, activation='relu')(self.outa)\n",
    "            self.attn_layer = AttentionLayer(name='attention_layer')\n",
    "            self.attn_out, self.attn_states = self.attn_layer([self.outv, self.outa], verbose=False)\n",
    "            print('attn_out:', self.attn_out.shape)\n",
    "            print('attn_states:', self.attn_states.shape)\n",
    "\n",
    "            \n",
    "            self.fusion=concatenate([self.attn_out, self.outv, self.outa],axis=-1)  # B, 200, 512\n",
    "            #self.fusion = Conv1D(512, 1)(self.fusion)\n",
    "            #self.fusion = Lambda(lambda x: K.expand_dims(x, axis=2))(self.fusion)\n",
    "            #self.fusion=Conv2DTranspose(256,(16,1),strides=(8,1),padding='same',data_format='channels_last')(self.fusion) # B, 1600, 256\n",
    "            #self.fusion = Lambda(lambda x: K.squeeze(x, axis=2), name='fusion_out')(self.fusion)\n",
    "            \n",
    "            #self.fusion=concatenate([self.fusion, self.outa],axis=-1)  # B, 200, 512\n",
    "            self.fusion=Conv1D(512,1)(self.fusion)\n",
    "        else:\n",
    "            self.fusion=concatenate([self.outv,self.outa],axis=-1)\n",
    "        \n",
    "        print('fusion:', self.fusion.shape)\n",
    "\n",
    "        '''self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        self.fusion=multi_head_self_attention(8,512)(self.fusion)\n",
    "        print('self attention fusion shape',self.fusion.shape)'''\n",
    "\n",
    "        self.fusion=Conv1D(256,1)(self.fusion)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=1,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=2,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=4,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=8,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=16,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=32,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=64,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=128,filters=256)\n",
    "\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=1,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=2,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=4,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=8,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=16,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=32,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=64,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=128,filters=256)\n",
    "\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=1,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=2,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=4,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=8,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=16,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=32,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=64,filters=256)\n",
    "        self.fusion=Conv_Block_Audio(self.fusion,dialation_rate=128,filters=256)\n",
    "        \n",
    "        #Decoding\n",
    "        #self.mask=Conv1D(256,1,activation='relu', name='mask')(self.fusion)\n",
    "        self.mask = Activation('relu')(self.fusion)\n",
    "        self.fusion=Multiply()([self.audio,self.mask])\n",
    "        self.decode = Lambda(lambda x: K.expand_dims(x, axis=2))(self.fusion)\n",
    "\n",
    "        #self.decode=Conv2DTranspose(256,(16,1),strides=(8,1),padding='same',data_format='channels_last')(self.decode)\n",
    "        self.decode=Conv2DTranspose(1,(40,1),strides=(20,1),padding='same',data_format='channels_last')(self.decode)\n",
    "        self.out = Lambda(lambda x: K.squeeze(x, axis=2), name='out')(self.decode)\n",
    "        print('Out:', self.out.shape)\n",
    "        \n",
    "        '''self.out_norm = vec_l2norm(self.out)\n",
    "        self.out_normalized = self.out/self.out_norm\n",
    "        self.out_denormalized = self.out_normalized*self.norm'''\n",
    "        \n",
    "        self.model=Model(inputs=[self.lipnet_model.input,self.audio_input_data],outputs=[self.out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Conv Out: (None, 50, 32, 32, 64)\n",
      "3D Conv Out Reshape: (None, 32, 32, 64)\n",
      "Resnet18 Out: (None, 1, 1, 512)\n",
      "Resnet18 Linear Out: (None, 256)\n",
      "Input to GRU: (None, 50, 256)\n",
      "GRU Out: (None, 50, 29)\n",
      "outv: (None, 1600, 256)\n",
      "outa: (None, 1600, 256)\n",
      "fusion: (None, 1600, 512)\n",
      "Out: (None, 32000, 1)\n"
     ]
    }
   ],
   "source": [
    "tasnet = TasNet(time_dimensions=200, frequency_bins=257, n_frames=50,\n",
    "                      attention=False, lstm=False, lipnet_pretrained=False,  train_lipnet=True)\n",
    "model = tasnet.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 32000, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_375 (Conv1D)             (None, 1600, 256)    10496       input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "channelwise_layer_norm_12 (Chan (None, 1600, 256)    512         conv1d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_380 (Conv1D)             (None, 1600, 256)    65792       channelwise_layer_norm_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_429 (Activation)     (None, 1600, 256)    0           conv1d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_203 (GlobalLa (None, 1600, 256)    512         activation_429[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_319 (Separable (None, 1600, 256)    66560       global_layer_norm_203[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_423 (Add)                   (None, 1600, 256)    0           channelwise_layer_norm_12[0][0]  \n",
      "                                                                 separable_conv1d_319[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_381 (Conv1D)             (None, 1600, 256)    65792       add_423[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_430 (Activation)     (None, 1600, 256)    0           conv1d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_204 (GlobalLa (None, 1600, 256)    512         activation_430[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_320 (Separable (None, 1600, 256)    66560       global_layer_norm_204[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "frames_input (InputLayer)       [(None, 50, 50, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_424 (Add)                   (None, 1600, 256)    0           add_423[0][0]                    \n",
      "                                                                 separable_conv1d_320[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "sequential_36 (Sequential)      (None, 50, 32, 32, 6 15936       frames_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_382 (Conv1D)             (None, 1600, 256)    65792       add_424[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda2 (Lambda)                (None, 32, 32, 64)   0           sequential_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_431 (Activation)     (None, 1600, 256)    0           conv1d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "model_31 (Model)                multiple             1451072     lambda2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_205 (GlobalLa (None, 1600, 256)    512         activation_431[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_avgpool_resnet (GlobalAv (None, 512)          0           model_31[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_321 (Separable (None, 1600, 256)    66560       global_layer_norm_205[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_resnet (Dense)            (None, 256)          131328      global_avgpool_resnet[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_425 (Add)                   (None, 1600, 256)    0           add_424[0][0]                    \n",
      "                                                                 separable_conv1d_321[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn_resnet (BatchNormalization)  (None, 256)          1024        dense_resnet[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_383 (Conv1D)             (None, 1600, 256)    65792       add_425[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda6 (Lambda)                (None, 50, 256)      0           bn_resnet[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 1600, 256)    0           conv1d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_378 (Conv1D)             (None, 50, 512)      131584      lambda6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_206 (GlobalLa (None, 1600, 256)    512         activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_424 (Activation)     (None, 50, 512)      0           conv1d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_322 (Separable (None, 1600, 256)    66560       global_layer_norm_206[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 50, 512)      2048        activation_424[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_426 (Add)                   (None, 1600, 256)    0           add_425[0][0]                    \n",
      "                                                                 separable_conv1d_322[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_314 (Separable (None, 50, 512)      264192      batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_384 (Conv1D)             (None, 1600, 256)    65792       add_426[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_418 (Add)                   (None, 50, 512)      0           conv1d_378[0][0]                 \n",
      "                                                                 separable_conv1d_314[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, 1600, 256)    0           conv1d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_425 (Activation)     (None, 50, 512)      0           add_418[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_207 (GlobalLa (None, 1600, 256)    512         activation_433[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 50, 512)      2048        activation_425[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_323 (Separable (None, 1600, 256)    66560       global_layer_norm_207[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_315 (Separable (None, 50, 512)      264192      batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_427 (Add)                   (None, 1600, 256)    0           add_426[0][0]                    \n",
      "                                                                 separable_conv1d_323[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_419 (Add)                   (None, 50, 512)      0           add_418[0][0]                    \n",
      "                                                                 separable_conv1d_315[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_385 (Conv1D)             (None, 1600, 256)    65792       add_427[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_426 (Activation)     (None, 50, 512)      0           add_419[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_434 (Activation)     (None, 1600, 256)    0           conv1d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 50, 512)      2048        activation_426[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_208 (GlobalLa (None, 1600, 256)    512         activation_434[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_316 (Separable (None, 50, 512)      264192      batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_324 (Separable (None, 1600, 256)    66560       global_layer_norm_208[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_420 (Add)                   (None, 50, 512)      0           add_419[0][0]                    \n",
      "                                                                 separable_conv1d_316[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_428 (Add)                   (None, 1600, 256)    0           add_427[0][0]                    \n",
      "                                                                 separable_conv1d_324[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_427 (Activation)     (None, 50, 512)      0           add_420[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_386 (Conv1D)             (None, 1600, 256)    65792       add_428[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 50, 512)      2048        activation_427[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_435 (Activation)     (None, 1600, 256)    0           conv1d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_317 (Separable (None, 50, 512)      264192      batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_209 (GlobalLa (None, 1600, 256)    512         activation_435[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_421 (Add)                   (None, 50, 512)      0           add_420[0][0]                    \n",
      "                                                                 separable_conv1d_317[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_325 (Separable (None, 1600, 256)    66560       global_layer_norm_209[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_428 (Activation)     (None, 50, 512)      0           add_421[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_429 (Add)                   (None, 1600, 256)    0           add_428[0][0]                    \n",
      "                                                                 separable_conv1d_325[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 50, 512)      2048        activation_428[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_387 (Conv1D)             (None, 1600, 256)    65792       add_429[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_318 (Separable (None, 50, 512)      264192      batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_436 (Activation)     (None, 1600, 256)    0           conv1d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_422 (Add)                   (None, 50, 512)      0           add_421[0][0]                    \n",
      "                                                                 separable_conv1d_318[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_210 (GlobalLa (None, 1600, 256)    512         activation_436[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_379 (Conv1D)             (None, 50, 256)      131328      add_422[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_326 (Separable (None, 1600, 256)    66560       global_layer_norm_210[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_8 (UpSampling1D)  (None, 1600, 256)    0           conv1d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_430 (Add)                   (None, 1600, 256)    0           add_429[0][0]                    \n",
      "                                                                 separable_conv1d_326[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1600, 512)    0           up_sampling1d_8[0][0]            \n",
      "                                                                 add_430[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_388 (Conv1D)             (None, 1600, 256)    131328      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_389 (Conv1D)             (None, 1600, 256)    65792       conv1d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_437 (Activation)     (None, 1600, 256)    0           conv1d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_211 (GlobalLa (None, 1600, 256)    512         activation_437[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_327 (Separable (None, 1600, 256)    66560       global_layer_norm_211[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_431 (Add)                   (None, 1600, 256)    0           conv1d_388[0][0]                 \n",
      "                                                                 separable_conv1d_327[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_390 (Conv1D)             (None, 1600, 256)    65792       add_431[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_438 (Activation)     (None, 1600, 256)    0           conv1d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_212 (GlobalLa (None, 1600, 256)    512         activation_438[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_328 (Separable (None, 1600, 256)    66560       global_layer_norm_212[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_432 (Add)                   (None, 1600, 256)    0           add_431[0][0]                    \n",
      "                                                                 separable_conv1d_328[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_391 (Conv1D)             (None, 1600, 256)    65792       add_432[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_439 (Activation)     (None, 1600, 256)    0           conv1d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_213 (GlobalLa (None, 1600, 256)    512         activation_439[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_329 (Separable (None, 1600, 256)    66560       global_layer_norm_213[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_433 (Add)                   (None, 1600, 256)    0           add_432[0][0]                    \n",
      "                                                                 separable_conv1d_329[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_392 (Conv1D)             (None, 1600, 256)    65792       add_433[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_440 (Activation)     (None, 1600, 256)    0           conv1d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_214 (GlobalLa (None, 1600, 256)    512         activation_440[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_330 (Separable (None, 1600, 256)    66560       global_layer_norm_214[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_434 (Add)                   (None, 1600, 256)    0           add_433[0][0]                    \n",
      "                                                                 separable_conv1d_330[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_393 (Conv1D)             (None, 1600, 256)    65792       add_434[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_441 (Activation)     (None, 1600, 256)    0           conv1d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_215 (GlobalLa (None, 1600, 256)    512         activation_441[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_331 (Separable (None, 1600, 256)    66560       global_layer_norm_215[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_435 (Add)                   (None, 1600, 256)    0           add_434[0][0]                    \n",
      "                                                                 separable_conv1d_331[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_394 (Conv1D)             (None, 1600, 256)    65792       add_435[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_442 (Activation)     (None, 1600, 256)    0           conv1d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_216 (GlobalLa (None, 1600, 256)    512         activation_442[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_332 (Separable (None, 1600, 256)    66560       global_layer_norm_216[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_436 (Add)                   (None, 1600, 256)    0           add_435[0][0]                    \n",
      "                                                                 separable_conv1d_332[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_395 (Conv1D)             (None, 1600, 256)    65792       add_436[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_443 (Activation)     (None, 1600, 256)    0           conv1d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_217 (GlobalLa (None, 1600, 256)    512         activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_333 (Separable (None, 1600, 256)    66560       global_layer_norm_217[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_437 (Add)                   (None, 1600, 256)    0           add_436[0][0]                    \n",
      "                                                                 separable_conv1d_333[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_396 (Conv1D)             (None, 1600, 256)    65792       add_437[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_444 (Activation)     (None, 1600, 256)    0           conv1d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_218 (GlobalLa (None, 1600, 256)    512         activation_444[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_334 (Separable (None, 1600, 256)    66560       global_layer_norm_218[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_438 (Add)                   (None, 1600, 256)    0           add_437[0][0]                    \n",
      "                                                                 separable_conv1d_334[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_397 (Conv1D)             (None, 1600, 256)    65792       add_438[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_445 (Activation)     (None, 1600, 256)    0           conv1d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_219 (GlobalLa (None, 1600, 256)    512         activation_445[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_335 (Separable (None, 1600, 256)    66560       global_layer_norm_219[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_439 (Add)                   (None, 1600, 256)    0           add_438[0][0]                    \n",
      "                                                                 separable_conv1d_335[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_398 (Conv1D)             (None, 1600, 256)    65792       add_439[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_446 (Activation)     (None, 1600, 256)    0           conv1d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_220 (GlobalLa (None, 1600, 256)    512         activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_336 (Separable (None, 1600, 256)    66560       global_layer_norm_220[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_440 (Add)                   (None, 1600, 256)    0           add_439[0][0]                    \n",
      "                                                                 separable_conv1d_336[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_399 (Conv1D)             (None, 1600, 256)    65792       add_440[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_447 (Activation)     (None, 1600, 256)    0           conv1d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_221 (GlobalLa (None, 1600, 256)    512         activation_447[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_337 (Separable (None, 1600, 256)    66560       global_layer_norm_221[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_441 (Add)                   (None, 1600, 256)    0           add_440[0][0]                    \n",
      "                                                                 separable_conv1d_337[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_400 (Conv1D)             (None, 1600, 256)    65792       add_441[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_448 (Activation)     (None, 1600, 256)    0           conv1d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_222 (GlobalLa (None, 1600, 256)    512         activation_448[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_338 (Separable (None, 1600, 256)    66560       global_layer_norm_222[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_442 (Add)                   (None, 1600, 256)    0           add_441[0][0]                    \n",
      "                                                                 separable_conv1d_338[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_401 (Conv1D)             (None, 1600, 256)    65792       add_442[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_449 (Activation)     (None, 1600, 256)    0           conv1d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_223 (GlobalLa (None, 1600, 256)    512         activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_339 (Separable (None, 1600, 256)    66560       global_layer_norm_223[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_443 (Add)                   (None, 1600, 256)    0           add_442[0][0]                    \n",
      "                                                                 separable_conv1d_339[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_402 (Conv1D)             (None, 1600, 256)    65792       add_443[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_450 (Activation)     (None, 1600, 256)    0           conv1d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_224 (GlobalLa (None, 1600, 256)    512         activation_450[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_340 (Separable (None, 1600, 256)    66560       global_layer_norm_224[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_444 (Add)                   (None, 1600, 256)    0           add_443[0][0]                    \n",
      "                                                                 separable_conv1d_340[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_403 (Conv1D)             (None, 1600, 256)    65792       add_444[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_451 (Activation)     (None, 1600, 256)    0           conv1d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_225 (GlobalLa (None, 1600, 256)    512         activation_451[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_341 (Separable (None, 1600, 256)    66560       global_layer_norm_225[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_445 (Add)                   (None, 1600, 256)    0           add_444[0][0]                    \n",
      "                                                                 separable_conv1d_341[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_404 (Conv1D)             (None, 1600, 256)    65792       add_445[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_452 (Activation)     (None, 1600, 256)    0           conv1d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_226 (GlobalLa (None, 1600, 256)    512         activation_452[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_342 (Separable (None, 1600, 256)    66560       global_layer_norm_226[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_446 (Add)                   (None, 1600, 256)    0           add_445[0][0]                    \n",
      "                                                                 separable_conv1d_342[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_405 (Conv1D)             (None, 1600, 256)    65792       add_446[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_453 (Activation)     (None, 1600, 256)    0           conv1d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_227 (GlobalLa (None, 1600, 256)    512         activation_453[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_343 (Separable (None, 1600, 256)    66560       global_layer_norm_227[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_447 (Add)                   (None, 1600, 256)    0           add_446[0][0]                    \n",
      "                                                                 separable_conv1d_343[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_406 (Conv1D)             (None, 1600, 256)    65792       add_447[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_454 (Activation)     (None, 1600, 256)    0           conv1d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_228 (GlobalLa (None, 1600, 256)    512         activation_454[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_344 (Separable (None, 1600, 256)    66560       global_layer_norm_228[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_448 (Add)                   (None, 1600, 256)    0           add_447[0][0]                    \n",
      "                                                                 separable_conv1d_344[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_407 (Conv1D)             (None, 1600, 256)    65792       add_448[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_455 (Activation)     (None, 1600, 256)    0           conv1d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_229 (GlobalLa (None, 1600, 256)    512         activation_455[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_345 (Separable (None, 1600, 256)    66560       global_layer_norm_229[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_449 (Add)                   (None, 1600, 256)    0           add_448[0][0]                    \n",
      "                                                                 separable_conv1d_345[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_408 (Conv1D)             (None, 1600, 256)    65792       add_449[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_456 (Activation)     (None, 1600, 256)    0           conv1d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_230 (GlobalLa (None, 1600, 256)    512         activation_456[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_346 (Separable (None, 1600, 256)    66560       global_layer_norm_230[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_450 (Add)                   (None, 1600, 256)    0           add_449[0][0]                    \n",
      "                                                                 separable_conv1d_346[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_409 (Conv1D)             (None, 1600, 256)    65792       add_450[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_457 (Activation)     (None, 1600, 256)    0           conv1d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_231 (GlobalLa (None, 1600, 256)    512         activation_457[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_347 (Separable (None, 1600, 256)    66560       global_layer_norm_231[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_451 (Add)                   (None, 1600, 256)    0           add_450[0][0]                    \n",
      "                                                                 separable_conv1d_347[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_410 (Conv1D)             (None, 1600, 256)    65792       add_451[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_458 (Activation)     (None, 1600, 256)    0           conv1d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_232 (GlobalLa (None, 1600, 256)    512         activation_458[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_348 (Separable (None, 1600, 256)    66560       global_layer_norm_232[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_452 (Add)                   (None, 1600, 256)    0           add_451[0][0]                    \n",
      "                                                                 separable_conv1d_348[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_411 (Conv1D)             (None, 1600, 256)    65792       add_452[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_459 (Activation)     (None, 1600, 256)    0           conv1d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_233 (GlobalLa (None, 1600, 256)    512         activation_459[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_349 (Separable (None, 1600, 256)    66560       global_layer_norm_233[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_453 (Add)                   (None, 1600, 256)    0           add_452[0][0]                    \n",
      "                                                                 separable_conv1d_349[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_412 (Conv1D)             (None, 1600, 256)    65792       add_453[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_460 (Activation)     (None, 1600, 256)    0           conv1d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_layer_norm_234 (GlobalLa (None, 1600, 256)    512         activation_460[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_350 (Separable (None, 1600, 256)    66560       global_layer_norm_234[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_454 (Add)                   (None, 1600, 256)    0           add_453[0][0]                    \n",
      "                                                                 separable_conv1d_350[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_461 (Activation)     (None, 1600, 256)    0           add_454[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 1600, 256)    0           channelwise_layer_norm_12[0][0]  \n",
      "                                                                 activation_461[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1600, 1, 256) 0           multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 32000, 1, 1)  10241       lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out (Lambda)                    (None, 32000, 1)     0           conv2d_transpose_7[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 7,597,697\n",
      "Trainable params: 7,583,873\n",
      "Non-trainable params: 13,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
