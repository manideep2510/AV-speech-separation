{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from keras import Model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback, ReduceLROnPlateau, EarlyStopping, ReduceLROnPlateau\n",
    "from callbacks import Metrics, learningratescheduler, earlystopping, reducelronplateau\n",
    "from plotting import plot_loss_and_acc\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read the images in numerical order\n",
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(spect1, spect2):\n",
    "    loss = tf.sqrt(tf.nn.l2_loss(spect1[:,:,:,0] - spect2[:,:,:,0]))\n",
    "    #loss = tf.sqrt(tf.nn.l2_loss(spect1 - spect2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LipNet(input_shape, pretrained=None, output_size = 28, absolute_max_string_len=32):\n",
    "        \n",
    "        '''if K.image_data_format() == 'channels_first':\n",
    "            input_shape = (img_c, frames_n, img_w, img_h)\n",
    "        else:\n",
    "            input_shape = (frames_n, img_w, img_h, img_c)'''\n",
    "\n",
    "        input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "\n",
    "        zero1 = ZeroPadding3D(padding=(1, 2, 2), name='zero1')(input_data)\n",
    "        conv1 = Conv3D(32, (3, 5, 5), strides=(1, 2, 2), kernel_initializer='he_normal', name='conv1')(zero1)\n",
    "        batc1 = BatchNormalization(name='batc1')(conv1)\n",
    "        actv1 = Activation('relu', name='actv1')(batc1)\n",
    "        drop1 = SpatialDropout3D(0.5)(actv1)\n",
    "        maxp1 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max1')(drop1)\n",
    "\n",
    "        zero2 = ZeroPadding3D(padding=(1, 2, 2), name='zero2')(maxp1)\n",
    "        conv2 = Conv3D(64, (3, 5, 5), strides=(1, 1, 1), kernel_initializer='he_normal', name='conv2')(zero2)\n",
    "        batc2 = BatchNormalization(name='batc2')(conv2)\n",
    "        actv2 = Activation('relu', name='actv2')(batc2)\n",
    "        drop2 = SpatialDropout3D(0.5)(actv2)\n",
    "        maxp2 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max2')(drop2)\n",
    "\n",
    "        zero3 = ZeroPadding3D(padding=(1, 1, 1), name='zero3')(maxp2)\n",
    "        conv3 = Conv3D(96, (3, 3, 3), strides=(1, 1, 1), kernel_initializer='he_normal', name='conv3')(zero3)\n",
    "        batc3 = BatchNormalization(name='batc3')(conv3)\n",
    "        actv3 = Activation('relu', name='actv3')(batc3)\n",
    "        drop3 = SpatialDropout3D(0.5)(actv3)\n",
    "        maxp3 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max3')(drop3)\n",
    "\n",
    "        resh1 = TimeDistributed(Flatten())(maxp3)\n",
    "\n",
    "        gru_1 = Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru1'), merge_mode='concat')(resh1)\n",
    "        gru_2 = Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru2'), merge_mode='concat')(gru_1)\n",
    "\n",
    "        # transforms RNN output to character activations:\n",
    "        dense1 = Dense(output_size, kernel_initializer='he_normal', name='dense1')(gru_2)\n",
    "\n",
    "        y_pred = Activation('softmax', name='softmax')(dense1)\n",
    "\n",
    "        #labels = Input(name='the_labels', shape=[absolute_max_string_len], dtype='float32')\n",
    "        #input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "        #label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "        #loss_out = CTC('ctc', [y_pred, labels, input_length, label_length])\n",
    "\n",
    "        model = Model(inputs=input_data, outputs=y_pred)\n",
    "        \n",
    "        if pretrained == True:\n",
    "            model.load_weights('/Users/manideepkolla/Downloads/unseen-weights178.h5')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoModel():\n",
    "\n",
    "    def __init__(self, filters,filters_audio, audio_ip_shape, video_ip_shape):\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.filters_audio=filters_audio       \n",
    "        self.audio_ip_shape = audio_ip_shape\n",
    "        self.video_ip_shape = video_ip_shape\n",
    "\n",
    "        self.conv1 = Conv2D(filters = filters, kernel_size = (7), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")\n",
    "        self.bn1 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv2 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")\n",
    "        self.bn2 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv3 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (2,2),\n",
    "                      activation = \"relu\")\n",
    "        self.bn3 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv4 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (4,4),\n",
    "                      activation = \"relu\")\n",
    "        self.bn4 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv5 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (8,8),\n",
    "                      activation = \"relu\")\n",
    "        self.bn5 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv6 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (16,16),\n",
    "                      activation = \"relu\")\n",
    "        self.bn6 = BatchNormalization(axis=-1)\n",
    "    \n",
    "\n",
    "        self.conv7 = Lambda(lambda x : tf.expand_dims(x, axis = -1))\n",
    "\n",
    "        self.conv8 = Lambda(lambda x: tf.image.resize_nearest_neighbor(x, size = (298, x.shape[-2])))\n",
    "        \n",
    "        #self.lipnet_model = LipNet(img_c=self.video_ip_shape[3], img_w=self.video_ip_shape[2], img_h=self.video_ip_shape[1], frames_n=self.video_ip_shape[0], absolute_max_string_len=32, output_size=28).build()\n",
    "\n",
    "    def FullModel(self, lipnet_pretrained):\n",
    "\n",
    "        ip = Input(shape = (self.audio_ip_shape[0], self.audio_ip_shape[1], 2)) #; print(\"input_audio\", ip.shape) \n",
    "        ip_embeddings_1 = Input(shape = (int(self.video_ip_shape[0]), int(self.video_ip_shape[1]),int(self.video_ip_shape[2]), int(self.video_ip_shape[3])))#; print(\"ip video\", ip_embeddings_1.shape)  #[75, 512]\n",
    "        #ip_embeddings_2 = Input(shape = (video_ip_shape[0], video_ip_shape[1])); print(\"ip video\", ip_embeddings_2.shape)  #[75, 512]\n",
    "\n",
    "        ip_magnitude = Lambda(lambda x : x[:,:,:,0],name=\"ip_mag\")(ip)#; print(\"ip_mag \", ip_magnitude.shape)  #takes magnitude from stack[magnitude,phase]\n",
    "        ip_phase = Lambda(lambda x : tf.expand_dims(x[:,:,:,1], axis = -1),name=\"ip_phase\")(ip)#; print(\"ip_phase \", ip_phase.shape)  #takes phase from stack[magnitude,phase]\n",
    "\n",
    "        ip_embeddings_1_expanded = Lambda(lambda x : tf.expand_dims(x, axis = -1))(ip_embeddings_1)\n",
    "        #ip_embeddings_2_expanded = Lambda(lambda x : tf.expand_dims(x, axis = -1))(ip_embeddings_2)\n",
    "\n",
    "        #audio_stream = self.AudioModel(ip)\n",
    "        conv = Conv2D(filters = self.filters_audio, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(ip) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 2, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 2, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 3, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 3, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 3, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio//12, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        audio_stream = BatchNormalization(axis=-1)(conv)\n",
    "        print('audio_stream', audio_stream.shape)\n",
    "\n",
    "        '''stream_1 = self.conv1(ip_embeddings_1)\n",
    "        stream_1 = self.bn1(stream_1)\n",
    "        stream_1 = self.conv2(stream_1)\n",
    "        stream_1 = self.bn2(stream_1)\n",
    "        stream_1 = self.conv3(stream_1)\n",
    "        stream_1 = self.bn3(stream_1)\n",
    "        stream_1 = self.conv4(stream_1)\n",
    "        stream_1 = self.bn4(stream_1)\n",
    "        stream_1 = self.conv5(stream_1)\n",
    "        stream_1 = self.bn5(stream_1)\n",
    "        stream_1 = self.conv6(stream_1)\n",
    "        stream_1 = self.bn6(stream_1)\n",
    "        h,w = stream_1.shape[1], stream_1.shape[2]\n",
    "        c=stream_1.shape[3]\n",
    "        print(h,w,c)\n",
    "        re=Lambda(lambda x: tf.reshape(x,shape=(-1,h*w,c)))(stream_1)\n",
    "        print(re.shape)\n",
    "        stream_2 = self.conv7(re) \n",
    "        video_stream_1 = self.conv8(stream_2)\n",
    "        print(video_stream_1.shape)'''\n",
    "        \n",
    "        #self.lipnet_model.load_weights('/Users/manideepkolla/Downloads/unseen-weights178.h5')\n",
    "        \n",
    "        '''x = self.lipnet_model.layers[-2].output\n",
    "        #x = Model(inputs = ip_embeddings_1, outputs=x).output\n",
    "        x = self.conv7(x)\n",
    "        video_stream_1 = self.conv8(x)\n",
    "        print(video_stream_1.shape)'''\n",
    "        \n",
    "        lipnet_model = LipNet(input_shape = (500,50,100,3), pretrained=lipnet_pretrained)\n",
    "        x = lipnet_model.output\n",
    "        x = Dense(128, kernel_initializer='he_normal', name='dense2')(x)\n",
    "        x = Dense(256, kernel_initializer='he_normal', name='dense3')(x)\n",
    "        x = self.conv7(x)\n",
    "        video_stream_1 = self.conv8(x)\n",
    "\n",
    "#         stream_2 = self.conv1(ip_embeddings_2)\n",
    "#         stream_2 = self.bn1(stream_2)\n",
    "#         stream_2 = self.conv2(stream_2)\n",
    "#         stream_2 = self.bn2(stream_2)\n",
    "#         stream_2 = self.conv3(stream_2)\n",
    "#         stream_2 = self.bn3(stream_2)\n",
    "#         stream_2 = self.conv4(stream_2)\n",
    "#         stream_2 = self.bn4(stream_2)\n",
    "#         stream_2 = self.conv5(stream_2)\n",
    "#         stream_2 = self.bn5(stream_2)\n",
    "#         stream_2 = self.conv6(stream_2)\n",
    "#         stream_2 = self.bn6(stream_2)\n",
    "#         stream_2 = self.conv7(stream_2)\n",
    "#         video_stream_2 = self.conv8(stream_2)\n",
    "\n",
    "        audio_flatten = TimeDistributed(Flatten())(audio_stream) \n",
    "        print(audio_flatten.shape)\n",
    "        video_flatten_1 = TimeDistributed(Flatten())(video_stream_1)\n",
    "        print(video_flatten_1.shape)\n",
    "        #video_flatten_2 = TimeDistributed(Flatten())(video_stream_2)\n",
    "\n",
    "        #print(\"video Streams \", video_stream_1.shape, video_stream_2.shape)\n",
    "        #print(\"Flatten Streams\", video_flatten_1.shape, video_flatten_2.shape, audio_flatten.shape)\n",
    "\n",
    "        concated = concatenate([audio_flatten, video_flatten_1], axis = 2) \n",
    "        print(\"concat shape \", concated.shape)\n",
    "\n",
    "        lstm = Bidirectional(LSTM(units = 64, return_sequences = True, activation = \"tanh\"))(concated)   \n",
    "        #;print(\"lstm\", lstm.shape)\n",
    "\n",
    "        flatten = Flatten()(lstm) \n",
    "        #;print(\"flatten \", flatten.shape)\n",
    "\n",
    "        dense = Dense(100, activation = \"relu\")(flatten)\n",
    "\n",
    "        dense = Dense(2 * self.audio_ip_shape[0] * self.audio_ip_shape[1], activation = \"sigmoid\")(dense) \n",
    "        #;print(\"dense final \",dense.shape)\n",
    "\n",
    "        combo_mask = Reshape([2 , self.audio_ip_shape[0], self.audio_ip_shape[1]])(dense) \n",
    "        #; print(\"combo_mask \", combo_mask.shape)\n",
    "        mask_1 = Lambda(lambda x : x[:,0])(combo_mask) \n",
    "        #;print(\"mask 1 \", mask_1.shape)\n",
    "        #mask_2 = Lambda(lambda x : x[:,1])(combo_mask) \n",
    "        #;print(\"mask 2 \", mask_2.shape)\n",
    "\n",
    "        output_mag_1 = Lambda(lambda x : tf.multiply(x[0], x[1]), name = \"mask_multiply_1\")([ip_magnitude, mask_1])#; print(\"output_mag_1\", output_mag_1.shape)\n",
    "        #output_mag_2 = Lambda(lambda x : tf.multiply(x[0], x[1]), name = \"mask_multiply_2\")([ip_magnitude, mask_2]) ; print(\"output_mag_2\", output_mag_2.shape)\n",
    "\n",
    "        output_mag_1 = Lambda(lambda x : tf.expand_dims(x, axis= -1), name= \"expand_dim_1\")(output_mag_1)#; print(\"output_mag_expand_1\", output_mag_1.shape)\n",
    "        #output_mag_2 = Lambda(lambda x : tf.expand_dims(x, axis= -1), name= \"expand_dim_2\")(output_mag_2) ; print(\"output_mag_expand_2\", output_mag_2.shape)\n",
    "\n",
    "        output_final_1 = Lambda(lambda x : tf.concat(values=[x[0], x[1]], axis = -1),name=\"concat_mag_phase_1\")([output_mag_1, ip_phase]) \n",
    "        #; print(\"output_final_1 \", output_final_1.shape)\n",
    "        #output_final_2 = Lambda(lambda x : tf.concat(values=[x[0], x[1]], axis = -1),name=\"concat_mag_phase_2\")([output_mag_2, ip_phase]) ; print(\"output_final_2 \", output_final_2.shape)\n",
    "\n",
    "        model = Model([ip, lipnet_model.input], [output_final_1])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv  (?, 298, 257, 96)\n",
      "conv  (?, 298, 257, 96)\n",
      "conv  (?, 298, 257, 96)\n",
      "conv  (?, 298, 257, 192)\n",
      "conv  (?, 298, 257, 192)\n",
      "conv  (?, 298, 257, 288)\n",
      "conv  (?, 298, 257, 288)\n",
      "conv  (?, 298, 257, 288)\n",
      "conv  (?, 298, 257, 8)\n",
      "audio_stream (?, 298, 257, 8)\n",
      "(?, 298, 2056)\n",
      "(?, 298, 256)\n",
      "concat shape  (?, 298, 2312)\n"
     ]
    }
   ],
   "source": [
    "model = VideoModel(256,96,(298,257,2),(500,50,100,3)).FullModel(lipnet_pretrained = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "lrate = 0.0001\n",
    "model.compile(optimizer = Adam(lr=lrate), loss = l2_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_list = sorted(glob.glob('/Users/manideepkolla/Downloads/test_fold/output/*'), key=numericalSort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataGenerator \n",
    "\n",
    "def DataGenerator(lips_filelist, masks_filelist, spects_filelist, batch_size):\n",
    "\n",
    "    L = len(files)\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that\n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            \n",
    "            X_lips = np.asarray([get_video_frames(fname) for fname in lips_filelist[batch_start:limit]])\n",
    "            \n",
    "            X_mask = np.asarray([np.load(fname) for fname in masks_filelist[batch_start:limit]])\n",
    "            \n",
    "            X_spect = np.asarray([np.load(fname) for fname in spects_filelist[batch_start:limit]])\n",
    "            \n",
    "            #X = seq.augment_images(X)\n",
    "            \n",
    "            yield X_lips, X_spect, X_mask\n",
    "\n",
    "            batch_start += batch_size\n",
    "            batch_end += batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callcack\n",
    "metrics = Metrics()\n",
    "learningratescheduler = learningratescheduler()\n",
    "earlystopping = earlystopping()\n",
    "reducelronplateau = reducelronplateau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save model checkpoints\n",
    "\n",
    "path = ''\n",
    "\n",
    "try:\n",
    "    os.mkdir('/home/manideep/models/'+ path)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "filepath='/home/manideep/models/' +  path+ '/weights-best.hdf5'\n",
    "checkpoint_save_weights = ModelCheckpoint(filepath, monitor='val_acc', save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Generator\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "history = model.fit_generator(DataGenerator(lips_filelist, masks_filelist, spects_filelist, batch_size),\n",
    "                steps_per_epoch = np.ceil((len(lips_filelist)/float(batch_size)),\n",
    "                epochs=epochs,\n",
    "                validation_data=DataGenerator(lips_filelist_val, masks_filelist_val, spects_filelist_val, batch_size), \n",
    "                validation_steps = np.ceil((len(lips_filelist_val)/float(batch_size)),\n",
    "                callbacks=[earlystopping, learningratescheduler, checkpoint_save_weights], verbose = 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
