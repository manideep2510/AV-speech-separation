{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/durga/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/durga/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/durga/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/durga/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/durga/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/durga/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras import Model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoModel():\n",
    "\n",
    "    def __init__(self, filters,filters_audio, audio_ip_shape, video_ip_shape):\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.filters_audio=filters_audio       \n",
    "        self.audio_ip_shape = audio_ip_shape\n",
    "        self.video_ip_shape = video_ip_shape\n",
    "\n",
    "        self.conv1 = Conv2D(filters = filters, kernel_size = (7), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")\n",
    "        self.bn1 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv2 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")\n",
    "        self.bn2 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv3 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (2,2),\n",
    "                      activation = \"relu\")\n",
    "        self.bn3 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv4 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (4,4),\n",
    "                      activation = \"relu\")\n",
    "        self.bn4 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv5 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (8,8),\n",
    "                      activation = \"relu\")\n",
    "        self.bn5 = BatchNormalization(axis=-1)\n",
    "\n",
    "        self.conv6 = Conv2D(filters = filters, kernel_size = (5), padding = \"same\", dilation_rate = (16,16),\n",
    "                      activation = \"relu\")\n",
    "        self.bn6 = BatchNormalization(axis=-1)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv7 = Lambda(lambda x : tf.expand_dims(x, axis = -1))\n",
    "\n",
    "        self.conv8 = Lambda(lambda x: tf.image.resize_nearest_neighbor(x, size = (298, x.shape[-2])))\n",
    "\n",
    "# \tdef AudioModel(ip, filters = 32, dropout = 0.2):\n",
    "        \n",
    "#         conv = Conv2D(filters = filters, kernel_size = (3,3), strides = (1,1), padding = \"same\", dpeilation_rate = (1,1),\n",
    "#                       activation = \"relu\")(ip) ; print(\"conv \", conv.shape)\n",
    "#         conv = BatchNormalization(axis=-1)(conv)\n",
    "#         #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "#         conv = Conv2D(filters = filters, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "#                       activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "#         conv = BatchNormalization(axis=-1)(conv)\n",
    "#         #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "#         conv = Conv2D(filters = filters, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "#                       activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "#         conv = BatchNormalization(axis=-1)(conv)\n",
    "#         #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "#         conv = Conv2D(filters = filters* 2, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "#                       activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "#         conv = BatchNormalization(axis=-1)(conv)\n",
    "#         #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "#         conv = Conv2D(filters = filters* 2, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "#                       activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "#         conv = BatchNormalization(axis=-1)(conv)\n",
    "#         #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "#         conv = Conv2D(filters = filters* 3, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "#                       activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "#         conv = BatchNormalization(axis=-1)(conv)\n",
    "#         #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "#         conv = Conv2D(filters = filters* 3, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "#                       activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "#         conv = BatchNormalization(axis=-1)(conv)\n",
    "#         #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "#         conv = Conv2D(filters = filters* 3, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "#                       activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "#         conv = BatchNormalization(axis=-1)(conv)\n",
    "#         #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "#         conv = Conv2D(filters = filters* 3, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "#                       activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "#         conv = BatchNormalization(axis=-1)(conv)\n",
    "#         #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "#         return conv\n",
    "\n",
    "    def FullModel(self):\n",
    "\n",
    "        ip = Input(shape = (int(self.audio_ip_shape[0]), int(self.audio_ip_shape[1]), 2)) #; print(\"input_audio\", ip.shape) \n",
    "        ip_embeddings_1 = Input(shape = (int(self.video_ip_shape[0]), int(self.video_ip_shape[1]),int(self.video_ip_shape[2])))#; print(\"ip video\", ip_embeddings_1.shape)  #[75, 512]\n",
    "        #ip_embeddings_2 = Input(shape = (video_ip_shape[0], video_ip_shape[1])); print(\"ip video\", ip_embeddings_2.shape)  #[75, 512]\n",
    "\n",
    "        ip_magnitude = Lambda(lambda x : x[:,:,:,0],name=\"ip_mag\")(ip)#; print(\"ip_mag \", ip_magnitude.shape)  #takes magnitude from stack[magnitude,phase]\n",
    "        ip_phase = Lambda(lambda x : tf.expand_dims(x[:,:,:,1], axis = -1),name=\"ip_phase\")(ip)#; print(\"ip_phase \", ip_phase.shape)  #takes phase from stack[magnitude,phase]\n",
    "\n",
    "        ip_embeddings_1_expanded = Lambda(lambda x : tf.expand_dims(x, axis = -1))(ip_embeddings_1)\n",
    "        #ip_embeddings_2_expanded = Lambda(lambda x : tf.expand_dims(x, axis = -1))(ip_embeddings_2)\n",
    "\n",
    "        #audio_stream = self.AudioModel(ip)\n",
    "        conv = Conv2D(filters = self.filters_audio, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(ip) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 2, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 2, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 3, kernel_size = (3,3), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 3, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio* 3, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        conv = BatchNormalization(axis=-1)(conv)\n",
    "        #conv = SpatialDropout2D(rate = dropout)(conv)\n",
    "        \n",
    "        conv = Conv2D(filters = self.filters_audio//12, kernel_size = (5,5), strides = (1,1), padding = \"same\", dilation_rate = (1,1),\n",
    "                      activation = \"relu\")(conv) ; print(\"conv \", conv.shape)\n",
    "        audio_stream = BatchNormalization(axis=-1)(conv)\n",
    "        print('audio_stream', audio_stream.shape)\n",
    "\n",
    "        stream_1 = self.conv1(ip_embeddings_1)\n",
    "        stream_1 = self.bn1(stream_1)\n",
    "        stream_1 = self.conv2(stream_1)\n",
    "        stream_1 = self.bn2(stream_1)\n",
    "        stream_1 = self.conv3(stream_1)\n",
    "        stream_1 = self.bn3(stream_1)\n",
    "        stream_1 = self.conv4(stream_1)\n",
    "        stream_1 = self.bn4(stream_1)\n",
    "        stream_1 = self.conv5(stream_1)\n",
    "        stream_1 = self.bn5(stream_1)\n",
    "        stream_1 = self.conv6(stream_1)\n",
    "        stream_1 = self.bn6(stream_1)\n",
    "        h,w = stream_1.shape[1], stream_1.shape[2]\n",
    "        c=stream_1.shape[3]\n",
    "        print(h,w,c)\n",
    "        re=Lambda(lambda x: tf.reshape(x,shape=(-1,h*w,c)))(stream_1)\n",
    "        print(re.shape)\n",
    "        stream_2 = self.conv7(re) \n",
    "        video_stream_1 = self.conv8(stream_2)\n",
    "        print(video_stream_1.shape)\n",
    "\n",
    "#         stream_2 = self.conv1(ip_embeddings_2)\n",
    "#         stream_2 = self.bn1(stream_2)\n",
    "#         stream_2 = self.conv2(stream_2)\n",
    "#         stream_2 = self.bn2(stream_2)\n",
    "#         stream_2 = self.conv3(stream_2)\n",
    "#         stream_2 = self.bn3(stream_2)\n",
    "#         stream_2 = self.conv4(stream_2)\n",
    "#         stream_2 = self.bn4(stream_2)\n",
    "#         stream_2 = self.conv5(stream_2)\n",
    "#         stream_2 = self.bn5(stream_2)\n",
    "#         stream_2 = self.conv6(stream_2)\n",
    "#         stream_2 = self.bn6(stream_2)\n",
    "#         stream_2 = self.conv7(stream_2)\n",
    "#         video_stream_2 = self.conv8(stream_2)\n",
    "\n",
    "        audio_flatten = TimeDistributed(Flatten())(audio_stream) \n",
    "        print(audio_flatten.shape)\n",
    "        video_flatten_1 = TimeDistributed(Flatten())(video_stream_1)\n",
    "        print(video_flatten_1.shape)\n",
    "        #video_flatten_2 = TimeDistributed(Flatten())(video_stream_2)\n",
    "\n",
    "        #print(\"video Streams \", video_stream_1.shape, video_stream_2.shape)\n",
    "        #print(\"Flatten Streams\", video_flatten_1.shape, video_flatten_2.shape, audio_flatten.shape)\n",
    "\n",
    "        concated = concatenate([audio_flatten, video_flatten_1], axis = 2) \n",
    "        #;print(\"concat shape \", concated.shape)\n",
    "\n",
    "        lstm = Bidirectional(LSTM(units = 64, return_sequences = True, activation = \"tanh\"))(concated)   \n",
    "        #;print(\"lstm\", lstm.shape)\n",
    "\n",
    "        flatten = Flatten()(lstm) \n",
    "        #;print(\"flatten \", flatten.shape)\n",
    "\n",
    "        dense = Dense(100, activation = \"relu\")(flatten)\n",
    "\n",
    "        dense = Dense(2 * self.audio_ip_shape[0] * self.audio_ip_shape[1], activation = \"sigmoid\")(dense) \n",
    "        #;print(\"dense final \",dense.shape)\n",
    "\n",
    "        combo_mask = Reshape([2 , self.audio_ip_shape[0], self.audio_ip_shape[1]])(dense) \n",
    "        #; print(\"combo_mask \", combo_mask.shape)\n",
    "        mask_1 = Lambda(lambda x : x[:,0])(combo_mask) \n",
    "        #;print(\"mask 1 \", mask_1.shape)\n",
    "        #mask_2 = Lambda(lambda x : x[:,1])(combo_mask) \n",
    "        #;print(\"mask 2 \", mask_2.shape)\n",
    "\n",
    "        output_mag_1 = Lambda(lambda x : tf.multiply(x[0], x[1]), name = \"mask_multiply_1\")([ip_magnitude, mask_1])#; print(\"output_mag_1\", output_mag_1.shape)\n",
    "        #output_mag_2 = Lambda(lambda x : tf.multiply(x[0], x[1]), name = \"mask_multiply_2\")([ip_magnitude, mask_2]) ; print(\"output_mag_2\", output_mag_2.shape)\n",
    "\n",
    "        output_mag_1 = Lambda(lambda x : tf.expand_dims(x, axis= -1), name= \"expand_dim_1\")(output_mag_1)#; print(\"output_mag_expand_1\", output_mag_1.shape)\n",
    "        #output_mag_2 = Lambda(lambda x : tf.expand_dims(x, axis= -1), name= \"expand_dim_2\")(output_mag_2) ; print(\"output_mag_expand_2\", output_mag_2.shape)\n",
    "\n",
    "        output_final_1 = Lambda(lambda x : tf.concat(values=[x[0], x[1]], axis = -1),name=\"concat_mag_phase_1\")([output_mag_1, ip_phase]) \n",
    "        #; print(\"output_final_1 \", output_final_1.shape)\n",
    "        #output_final_2 = Lambda(lambda x : tf.concat(values=[x[0], x[1]], axis = -1),name=\"concat_mag_phase_2\")([output_mag_2, ip_phase]) ; print(\"output_final_2 \", output_final_2.shape)\n",
    "\n",
    "        model = Model([ip, ip_embeddings_1], [output_final_1])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv  (?, 298, 257, 96)\n",
      "conv  (?, 298, 257, 96)\n",
      "conv  (?, 298, 257, 96)\n",
      "conv  (?, 298, 257, 192)\n",
      "conv  (?, 298, 257, 192)\n",
      "conv  (?, 298, 257, 288)\n",
      "conv  (?, 298, 257, 288)\n",
      "conv  (?, 298, 257, 288)\n",
      "conv  (?, 298, 257, 8)\n",
      "audio_stream (?, 298, 257, 8)\n",
      "50 100 256\n",
      "(?, 5000, 256)\n",
      "(?, 298, 256, 1)\n",
      "(?, 298, 2056)\n",
      "(?, 298, 256)\n"
     ]
    }
   ],
   "source": [
    "model = VideoModel(256,96,(298,257,2),(50,100,500)).FullModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataGenerator \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Generator\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
